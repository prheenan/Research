\chapter{\sLabel{Intro}Introduction}
In single-molecule force spectroscopy (\singlemol{}) experiments, a force probe attaches to a molecule and stretches it while measuring the relationship between force and extension over time (\fRef{Cartoon}). These data are transformed into information such as kinetic rates of processive enzymes,\citePRH{comstock_direct_2015} protein-ligand bond strength, \citePRH{yuan_energy_2000} and the energy landscapes of proteins and nucleic acids \citePRH{dudko_Theory_2008}. The location and properties of the \textit{ruptures} in the data (see \fRef{Rupture}) are required for applying polymer models to the molecule and determining the molecular energy landscape.

Atomic force microscopy (AFM) is a powerful tool for studying the mechanical properties of biological molecules.  AFM can resolve sub-nanometer molecular structure such as the major and minor grooves of DNA,\citePRH{ido_beyond_2013} lattice structure of membrane-bound proteins,\citePRH{muller_surface_1999} and real-time motion of motor proteins\citePRH{ando_high-speed_2007}. As a force spectroscopy technique, AFM is capable of dynamic experiments such as measuring the unfolding and refolding kinetics of single proteins,\citePRH{he_direct_2015} unzipping double-stranded DNA,\citePRH{krautbauer_Unzipping_2003} and determing the unfolding and refolding pathways for membrane proteins\citePRH{yu_hidden_2017}. The viability of AFM in a wide range of temperatures, solvents, and other environmental variables makes it attractive for studying biological systems. 

During an \singlemol{}-AFM experiment, a cantilever-bound tip with a characteristic radius of a few nanometers interacts with a sample (\fRef{Cartoon}). The interaction is recorded via an optical lever arm system\cite{meyer_novel_1998} in which the displacement of the tip is measured via deflection of a laser focused on the cantilever. A calibrated tip can record interaction forces from piconewtons to nanonewtons. 

\begin{figure}[htpb]
\caption[Diagram of AFM attachment geometry]{\fLabel{Cartoon}Diagram of tip attachment geometry. \subref{A} A diagram of an AFM tip and a force-extension curve corresponding to no attachments. \subref{B} As (A), except illustrating a single attachment. \subref{C} As (A), except illustrating multiple attachments. For all subplots, the force changes color at the location of a tagged event, event location are denoted by a green arrow, and the raw data is plotted along with the data smoothed by a 1000-point, second order Savitsky-Golay filter. The colored bars above each force plot indicates the event status.}
\centering
\includegraphics[width=\figwidth]{../Figures/Finals/cartoon.pdf}% Here is how to import EPS art
\end{figure}

The analysis and interpretation of \singlemol{} experiments is limited by the attachment of the probe to the molecule of interest. Data acquisition is dependent on attachment between the probe and the molecule. In AFM, quality attachments between the tip and the sample may occur less than one curve in tens of thousands.\citePRH{bosshart_reference-free_2012} Though strategies exist to improve attachment rates by coating the AFM tip with a molecule that binds readily to the sample of interest,\cite{walder_robert_rapid_nodate} the majority of the data taken is still uninterpretable and must be removed. Although a trained human is capable of sorting \singlemol{} data and locating possible events (see \fRef{Rupture}), this process is time-consuming and not scientifically reproducible. Excluding data without events and identifying the locations of events within data is a major challenge in \singlemol{} data management and analysis.

Methods exist to automate manually sorting \singlemol{} data and detect sample unfolding or unbinding events. Automation removes the burden of manual data filtering and improves scientific reproducibility. Automation techniques include aligning by the contour length at each extension by applying polymer models;\citePRH{bosshart_reference-free_2012,kuhn_automated_2005} thresholding based on signal,or noise characteristics;\citePRH{gergely_semi-automatized_2001,roduit_openfovea:_2012} and classification based on transformations of the data into frequency or derivative space \citePRH{kasas_fuzzy_2000,garcia-masso_automated_2016,benitez_searching_2017}. These methods do provide an increased degree of autonomy, but their use is limited by their lack of generalization and interpretation. In particular, contour-length alignment algorithms bias results towards the dominant features and necessarily require a polymer model for the contour length as a function of force and extension. In \singlemol{} studies which apply forces to biomolecules with no existing theoretical polymer model or experiments focusing on rare behavior of a biomolecule, alignment algorithms will have limited use.  Thresholding and classification-based algorithms generally require optimizing many hard-to-interpret parameters. As we show below, these methods do not generalize well to the typical range of \singlemol{} data (\fRef{Performance}).

This paper describes a new method based on machine learning for detecting events in \singlemol{} force-extension curves.  The algorithm, named \name{} (\acronym{}), requires no \textit{a priori} knowledge of the polymer under study, does not bias interpretation of the data towards the dominant behavior of the data, and has two easy-to-interpret parameters which generalize well to typical \singlemol{} data ranges. \name{} is designed to make few assumptions about the data, operate over a wide range of AFM data, and require a small time and memory footprint compared to existing techniques.

 The first part of the paper describes the sample preparation, data acquisition, and data annotation needed to capture the unbinding of functionalized double-stranded DNA from functionalized AFM cantilevers (\fRef{Cartoon}).  The unbinding events in the force-extension curves are then manually annotated at multiple pulling velocities, effective contour lengths, and events per curve (see \tRef{statistics}). Finally, the details and improved performance of \name{} are described. 

\chapter{\sLabel{Materials}Materials and Methods}

\section{Sample Preparation}

Site-specific chemistry is used to improve the acquisition rate and quality of data. The procedure for surface, sample, and cantilever preparation has been described elsewhere\cite{walder_robert_rapid_nodate} and in \sRef{SampleDetails}. Briefly, through polymerase chain reaction, double-stranded DNA is functionalized with Dibenzocyclooctyl (DBCO) at one end to ensure a covalent bond with an azide-functionalized surface. The polymer is also functionalized with biotin at the opposite end to ensure a specific but reversible bond with a streptavidin-coated cantilever. These two bonds ensure the tip-DNA bond is broken before the surface-DNA bond, preventing tip contamination. 

\section{\sLabel{Surface}Atomic force microscopy}

All atomic force microscopy measurements were carried out using an Asylum Cypher \supply{Asylum Research}{Cypher ES}. The spring constant and sensitivity were determined using the equipartition theorem method.\citePRH{hutter_calibration_1993} All measurements were carried out with a 2 second pause at the surface. To promote molecular attachments to the tip, measurements were taken over a series of square, \ValUnit{25}{\textmu{}m} long grids at points separated by 1\textmu{}m. The stage was translated to a new grid point after measuring three force-extension curves. 

\section{\sLabel{Annotation}Data annotation}


\begin{figure}[htpb]
\caption[Definition of rupture force and loading rate]{\fLabel{Rupture} Defining the rupture and its associated properties. \subref{A} A force extension curve with a shadow over an event. The overlayed curve is the data smoothed by a 1000-point, second order Savitsky-Golay filter. \subref{B} The shadowed region of (A), with a linear fit of the data in region immediately proceeding the rupture region, which is shadowed. \subref{C} The shadowed region from (B). The rupture point and rupture force and loading rate are defined using the data and the fit, as described in the text. For all subplots, the force changes color at the location of a tagged event, and the event location is marked by a green arrow. }
\centering
\includegraphics[width=0.5\linewidth]{../Figures/Finals/ruptures.pdf}% Here is how to import EPS art
\end{figure}

Two hundred force-extension curves with events were obtained at three different pulling velocities (\ValUnit{100}{nm/s}, \ValUnit{500}{nm/s}, \ValUnit{1000}{nm/s}). The start and end of each event in a curve, as indices offset from the start of the curve, were obtained through manual annotation. The curves and the events were saved into comma-separated value files. More statistical information on the data, including curve length and number of events per curve, is given in \tRef{statistics}.

The expected rupture forces and loading rates were calculated from the annotated data. This process is shown graphically in \fRef{Rupture}. The region leading up to the event start was fit by a line, with the region length set to $\tau$ (see \tRef{Parameters}). The loading rate was assigned to the line's slope, and the rupture force was calculated by the value of the line at the time value where the unfiltered data was last above the line. This is the same procedure used to calculate the loading rate and rupture force of predicted events in \fRef{Performance}. 



\section{\sLabel{Algorithm}Algorithm Design and Analysis}

All timing and tuning results were obtained via a desktop with 16GB of RAM, a 3.7GHz i7-4790 CPU, and a 1TB hard drive. 

\subsection{\sLabel{Metrics}Algorithm description}

\name{} improves on previous methods by using information present in the data collected during the approach of the AFM cantilever to the surface-bound molecules (\fRef{FeatherExample}).  \fRef{Code} lists the psuedocode for the method. The algorithm is based on a probabilistic model of a signal lacking any events, the \textit{no-event model}, described in \sRef{DesignDetails}. The algorithm has the following basic steps:

\begin{enumerate}
\item Estimate the no-event parameters (see \fRef{FeatherExample}) from the approach curve.
\item Fit the no-event model to the retract curve.
\item Calculate the upper bound on the probability of each retract point given the model.
\item Update the probability by Bayesian inference to remove false positives
\item Report contiguous regions with probabilities lower than a user-specific threshold as events.
\end{enumerate}

 In summary, the algorithm calculates an upper bound on the probability of no event occurring at each time point, using parameters estimated from the approach portion of the curve (see \sRef{DesignDetails}) and a smoothing parameter from the user (see \tRef{Parameters}). The probability at each point is then iteratively updated in order to remove the effect of adhesions and other false-positives. Note this last step is the only step specific to \singlemol{}. As shown in \fRef{FeatherExample}, the result is a probability at each time point which drops from one towards zero near events. A threshold probability is set by the user or optimized by a tuning routine (see \sRef{Tuning} and \tRef{Parameters}). Contiguous regions of time with probabilities below the threshold are considered having a single event, and the rupture properties are determined within each region as described in \sRef{Annotation}.


\begin{table}
\caption[Algorithm parameters]{\tLabel{Parameters} The names and definitions of the parameters used by \name{}}
\begin{tabularx}{\textwidth}{ l | l | l | l  }
\hline \hline
Name & Meaning  & Value used in this work \e
$\tau$ & Number of points used for spline grid smoothing & 2\% of the curve length \e
threshold & Probability threshold above which to reject events  & Determined by tuning (see \fRef{Tuning}) \e
\end{tabularx}
\end{table}


\subsection{\sLabel{Compare}Choice of competing methods}

The following two algorithms were chosen for comparison to \name{}: 

\begin{itemize}
\item The AFM-specific `event\_find' routine from the OpenFovea AFM analysis package.\citePRH{roduit_openfovea:_2012}
\item The general-purpose `find\_peaks\_cwt' method from the Scientific Python package.\citePRH{Jones_SciPy:_2001}
\end{itemize}

 These methods were chosen to provide a representative sample of the viable techniques used in AFM data analysis. Unlike quadratic alignment algorithms in contour length space, these methods scale like O(N) and O(N$\cdot\log$(N)) respectively, where N is the length of a curve to be analyzed. Linear or near-linear scaling is desirable (see \fRef{Timing}) for analyzing hundreds of force-extension curves of millions of points each (see \tRef{statistics}). These baselines represent two common approaches to event detection in AFM, since the OpenFovea method is a thresholding algorithm, and the Scientific Python method is an algorithm which uses wavelet transformations. 

\subsection{\sLabel{Metrics}Performance Metrics}

Two metrics were used for comparing the event-finding performance of \name{} with the human-annotated data. The metrics we report are listed in \tRef{metrics}. The event error metric, $P_{85}$, is the 85th percentile of relative error (see \fRef{DistanceMetric}) between predicted and true event locations.  The rupture \BccLong{}, $1-\braket{d_{(\nu,F),t}^{\frac{1}{2}}|d_{(\nu,F),p}^{\frac{1}{2}}}$, reports the mistmatch between the true and predicted distribution over loading rates and rupture forces. 


\begin{table}
\caption[Definition of algorithmic performance metrics]{\tLabel{metrics} The definitions of the performance metrics reported. The metrics are bolded, and the quantities that they depend on are listed first. BCC stands for \BccLong{}.  Throughout, `k' refers to the (arbitrary) index of force-extension curve, and `i' and `'j' refer to either true or predicted. For example, $d_{t\rightarrow p,4}$ represents the distances from the true to the predicted events in force-extension curve 4, and $d_{(\nu,F),p}$ represents the 2-d distribution of predicted points in the space of loading rates and rupture forces.  }
\begin{tabularx}{\textwidth}{ l | l | l | l  }
\hline \hline
Name & Notation  & Range & \text{Optimum} \e 
$x_k$ & \text{total displacement of the force-extension curve} & \na & \na\\ \hline 
$d_{i\rightarrow j,k}$ & \text{distribution of distances in `k' from `i' ruptures } & \na &\na \\ 
& \text{to the closest `j' ruptures in or $x_k$ if none } &  & \\\hline 
$P_{\text{x}}$ &  \text{the `x'-th percentile of the concatenation of } & \na & \na \\
& $\frac{1}{x_k}d_{t\rightarrow p,k}$ \text{ and } $\frac{1}{x_k}d_{p\rightarrow t,k}$ \text{ over all k }  &&  \\ \hline 
$\nu_i$ & \text{histogram of `i' loading rates over all k} & \na & \na \\\hline 
$F_i$ & \text{histogram of `i' rupture forces over all k} & \na & \na \\\hline 
$d_{(\nu,F),i}$ & \text{joint histogram of $\nu_i$ and $F_i$ divided} & \na & \na \\
& \text{by the number of curves} && \\\hline \hline 
\textbf{relative event error} & P$_{85}$ &   [0,1] & 0 \e
\textbf{rupture BCC} & 1-$\braket{d_{(\nu,F),t}^{\frac{1}{2}}|d_{(\nu,F),p}^{\frac{1}{2}}}$ & [0,1] & 0 \\
\end{tabularx}
\end{table}

\begin{figure}[htpb]
\caption[Distance metric illustration]{\noindent\fLabel{DistanceMetric} Distance metric illustration. \subref{A} A force extension curve with two events, marked by green triangles, a predicted event location denoted by a dashed line, and examples of the distances in \tRef{metrics} shown as labelled arrows. The predicted event is not the output from any algorithm and is for illustration only. \subref{B} The distribution of distances obtained by concatenating the distances obtained from many curves as in (A). }
\centering
\includegraphics[width=\figwidth]{../Figures/Finals/no_event_distances.pdf}% Here is how to import EPS art
\end{figure}



\subsection{\sLabel{Tuning}Algorithm tuning}

All three algorithms were tuned using 5-fold cross validation. Cross validation was performed at fifteen log-spaced parameters over the useful parameter range of the algorithms (\fRef{Tuning}). The parameter value minimizing the total number of missing and extra events for an algorithm was considered the algorithm's best parameter. Data shown in the results consists of the concatenation of all validation folds for each algorithm's best parameter. 

Since tuning the baselines on the full dataset using our computer would have required more than eight cpu-months (compared to $\approx$1.5 cpu-days for \name{}, see \fRef{Timing}), a smaller subset of data was used for comparing the algorithms. In particular, the subset of the data with the smallest number of points per curve \textemdash{} 200 curves with v=\ValUnit{1000}{nm/s}, N$\approx1\times10^{5}$ (see \tRef{statistics}) \textemdash{} was used for results comparing \name{} to the baselines. \name{} was also tuned separately on the larger, more complex dataset, with similar results to those reported in the rest of the paper (\fRef{LargeDataset}). This demonstrates that \name{} generalizes well to a wide range of data sets sizes and experimental parameters.

\chapter{\sLabel{Results}Results}

\section{\sLabel{Timing}Algorithmic time complexity}

\fRef{Timing} compares the runtimes, T(n), of \name{} and the baselines. As expected, the runtime of each algorithm is roughly linear in the thousands to millions of points, with \name{} having a roughly tenfold better asymptotic slope.  

\begin{figure}[htpb]
\caption[Runtime versus length of curve]{\noindent\fLabel{Timing} Big-O runtime of each algorithm is approximately linear. \subref{A} The runtime per curve versus number of points in the curve, T(N), for each algorithm is plotted as points. Lines around the data show the best-fit upper and lower bounds of the form T$_{\mathrm{upper}}$(n) = a$_0$ + 2a$_1$n  and T$_{\mathrm{lower}}$(n) = a$_0$ + $\frac{1}{2}$a$_1$n. \subref{B} The linear constants $a_1$, representing the asymptotic runtime per data point, for each algorithm from (A) are plotted. }
\centering
\includegraphics[width=\figwidth]{../Figures/Finals/timing.pdf}% Here is how to import EPS art
\end{figure}

\section{\sLabel{Performance}Algorithmic event detection performance}

\tRef{AppliedMetrics} lists the performance metrics for each algorithm. This section describes the metrics in more detail for each algorithm. 

\fRef{PerformanceFEATHER} shows the event-detection performance of \name{}. The distributions of the two types of relative distance errors, as defined in \fRef{DistanceMetric} and \tRef{metrics}, exhibit a higher degree of symmetry than the baselines (see below). This symmetry is due to a low false-positive rate, since false-positives skew the distances from predicted to true points (d$_{\mathrm{p}\rightarrow\mathrm{t}}$). In addition, the error distribution is closer to zero than the baselines, indicating most errors are a small fraction of the length of the curve. Finally, \fRef{DistanceMetric} shows good agreement between \name{}'s predicted and the true two-dimensional distributions over rupture forces and loading rates.

The baselines do not perform as well as \name{}. \fRef{PerformanceFovea} and \fRef{PerformanceScipy} are identical to \fRef{PerformanceFEATHER}, but they describe the performance of the Open Fovea and Scientific Python baselines, respectively. Open Fovea's relative distance error distribution is heavily skew-right and asymmetric between the two error types, indicating many false positives. The same distribution for Scientific Python is more symmetric between error types, indicating fewer false positives than Open Fovea. However, the distance error distribution for Scientific Python has many points near 1, indicating a high error in predicted event location. Both baselines fail to accurately reproduce the expected and predicted distribution over rupture forces and loading rates.

As defined by \tRef{metrics}, relative to the best baseline \name{} improves the relative and absolute event error by a factor of 100 and improves the \BccLong{} by a factor of 8. For completeness, \fRef{Performance} lists the performance of all three algorithms on a single page.

\begin{table}
\caption[Algorithm performance]{\tLabel{AppliedMetrics} Performance metrics across the three algorithms. The optimal algorithm row for each metric is highlighted in bold, depending on if the metric optimum is low (denoted by a $\downarrow$ next to the name) or high (denoted by a $\uparrow$ next to the name).} 
\begin{tabularx}{\textwidth}{ l || l | l }
\hline \hline
 & Rupture BCC ($\downarrow$) & Relative event error P$_{85}$ ($\downarrow$)\e\hline 
FEATHER & \textbf{0.0403} & \textbf{0.00494}\e
Open Fovea & 0.633 & 0.58\e
Scientific Python & 0.349 & 0.514\e
\end{tabularx}
\end{table}



\begin{figure}[htpb]
\caption[\name{} Performance]{\noindent\fLabel{PerformanceFEATHER}Performance of \name{} compared to the baseline algorithms. \subref{A} The distributions of distances from predicted to true points d$_{\mathrm{p}\rightarrow\mathrm{t}}$ and from true to predicted points, d$_{\mathrm{t}\rightarrow\mathrm{p}}$ for \name{}. \subref{B} \name{}'s two-dimensional distribution of true and predicted rupture force and loading rate, as defined in \fRef{Rupture}. \subref{C,D} The histograms of rupture forces and loading rates, respectively, for \name{}.  \subref{E} The metrics defined in \tRef{metrics}. }
\centering
\includegraphics[width=\figwidth]{../Figures/Finals/FEATHER.pdf}% Here is how to import EPS art
\end{figure}

\begin{figure}[htpb]
\caption[Open Fovea Performance]{\noindent\fLabel{PerformanceFovea}Performance of the Open Fovea baseline. \subref{A-E}: As in \fRef{PerformanceFEATHER}, but for the Open Fovea baseline.}
\centering
\includegraphics[width=\figwidth]{../Figures/Finals/OpenFovea}% Here is how to import EPS art
\end{figure}



\begin{figure}[htpb]
\caption[Scientific Python Performance]{\noindent\fLabel{PerformanceScipy}Performance of the Scientific Python baseline. \subref{A-E}: As in \fRef{PerformanceFEATHER}, but for the Scientific Python baseline. }
\centering
\includegraphics[width=\figwidth]{../Figures/Finals/ScientificPython}% Here is how to import EPS art
\end{figure}


\chapter{\sLabel{Discussion}Discussion}


 \name{} provides order-of-magnitude improvements in both speed and physically-relevant metrics for algorithm performance, relative to the baselines presented. As shown in \fRef{LargeDataset}, \name{} also generalizes well to more complex \singlemol{} data.  

This work applied \name{} to unfolding in \singlemol{} data, but the algorithm could be generalized to a wider array of applications. Changing \name{} to search for refolding events in \singlemol{} data is a natural and useful generalization. In addition, domain-specific models could be combined with \name{} to further filter data, based on the specific experiment. For example, an experimenter could attempt to measure the force-extension relationship of a DNA hairpin of contour length \ValUnit{100}{nm}. After first obtaining all rupture locations in the data via \name{}, the experimenter could fit a polymer model to each curve up to final rupture to obtain the contour length, then remove all data with contour lengths outside of \ValUnit{(100$\pm \epsilon$)}{nm}, where $\epsilon$ is a small number. By predicting where events occur without providing any domain-specific model of the event, \name{} is one tool in a longer \singlemol{} analysis pipeline.

\name{} could be used in different scientific domains than \singlemol{}. To reduce the risk of overfitting to a specific type of \singlemol{} experiment, \name{} purposefully makes no assumptions about domain-specific data models (e.g. a polymer model for the force-extension relationship of DNA), except the removal of \singlemol{} domain-specific false positives. The step which removes false positive could be changed or removed to fit the data application. \singlemol{} data is a natural application for \name{}, since each retract curve, with its scientifically interesting data, is paired with an approach curve which is assumed lacking any events. The parameters needed to estimate \name{}'s probability bound are estimated from the approach curve. Since these parameters are all \name{} needs, the algorithm could be a powerful tool in domains besides \singlemol{}. \name{} only requires estimating the relevant parameters (\fRef{FeatherExample}) and defining events by discontinuous derivatives in otherwise continuous time series data. \name{}'s order-of-magnitude improvements in event detection improves the quality and reproducibility of event detection in time series data.
