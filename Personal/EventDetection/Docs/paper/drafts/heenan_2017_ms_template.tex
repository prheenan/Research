% ****** Start of file aipsamp.tex ******
%
%   This file is part of the AIP files in the AIP distribution for REVTeX 4.
%   Version 4.1 of REVTeX, October 2009
%
%   Copyright (c) 2009 American Institute of Physics.
%
%   See the AIP README file for restrictions and more information.
%
% TeX'ing this file requires that you have AMS-LaTeX 2.0 installed
% as well as the rest of the prerequisites for REVTeX 4.1
%
% It also requires running BibTeX. The commands are as follows:
%
%  1)  latex  aipsamp
%  2)  bibtex aipsamp
%  3)  latex  aipsamp
%  4)  latex  aipsamp
%
% Use this file as a source of example code for your aip document.
% Use the file aiptemplate.tex as a template for your document.
\documentclass[%
  aip,12pt,tightenlines,
  amsthm,
 amsmath,amssymb
]{article}
\usepackage{braket}
% use utf-8 for  the input encoding (so the bibliography isnt terrible)
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
% allow for break spaces...
% defines \textmu, which is now what inputenx seems to use for Î¼ - probably due inpmath.. also \textdegree... but not \textrho. Need utf - BOM
\usepackage{textcomp} 
\usepackage{textgreek}
\usepackage[greek,english]{babel}
% lstlisting: for code
\usepackage{listings}
% lstset: for stting colors of stuff
\lstset{language=python,mathescape,
  frame = single,
  basicstyle=\ttfamily,
  keywordstyle=\color{blue}\ttfamily,
  stringstyle=\color{red}\ttfamily,
  commentstyle=\color{green}\ttfamily}
\usepackage{dcolumn}% Align table columns on decimal point
\usepackage{bm}% bold math
% amsmath: for align, etc
\usepackage{amsmath}
%\usepackage[mathlines]{lineno}% Enable numbering of text and display math
%\linenumbers\relax % Commence numbering lines
\usepackage{txfonts}
% use natbib / superscripts
\usepackage[super]{natbib}
\bibliographystyle{unsrtnat}
\usepackage{tabularx}
% hyperref: enable clicking on citations
\usepackage{hyperref}
\usepackage{titlesec}
% gensymb: for degree
\usepackage{gensymb}
% use times new roman
% http://tex.stackexchange.com/questions/153168/how-to-set-document-font-to-times-new-roman-by-command
\usepackage{times}
% 'Thesis margins should be 1 inch from all edges.'
% 1 inch margins
% http://kb.mit.edu/confluence/pages/viewpage.action?pageId=3907057
\usepackage[margin=1in]{geometry}
\usepackage{graphicx}% Include figure files
% reducing heading madness
% http://tex.stackexchange.com/questions/53338/reducing-spacing-after-headings
\newcommand{\captionspacing}[0]{4pt plus 2pt minus 2pt}
\titlespacing\section{0pt}{\captionspacing}{\captionspacing}
\titlespacing\subsection{0pt}{\captionspacing}{\captionspacing}
\titlespacing\subsubsection{0pt}{\captionspacing}{\captionspacing}

% put the page number on the right handside
% http://tex.stackexchange.com/questions/56316/top-right-side-page-numbering
\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhf{}
\fancyhead[R]{\thepage}
% indent *all* paragraphs, not just after first
% "The first line of paragraphs or footnotes is indented uniformly in the 
% thesis.''
\usepackage{indentfirst}

\newcommand{\ndiffn}[3]{\frac{\partial^{#3}#1}{\partial^{#3}#2}}
\newcommand{\diffn}[2]{\ndiffn{#1}{#2}{}}
\newcommand{\eqs}[1]{
\begin{align*} 
\begin{split}
#1
\end{split}					
\end{align*}}

\newcommand{\pFig}[3]{
\begin{figure}[h!]
\centering
\pcaption{#2}
\boxed{\includegraphics[width=0.75\textwidth]{#1}}
\label{figure:#3}
\end{figure}}



\newcommand{\eqlab}[2]{
\begin{equation}
\label{equation:#2}
\begin{split}
#1
\end{split}
\end{equation}
}


\newcommand{\brac}[1]
{
  \Big[ #1 \Big]
}

\newcommand{\tab}[2]
{
\begin{tabular}[h!]{#1}
\hline
#2
\end{tabular}
}

\newcommand{\e}[0]{\\ \hline}

\newcommand{\pMat}[1]{
 \left[ \begin{array}
#1 \end{array} \right]
}

% for making specific references.
\newcommand{\tRef}[1]{Table \ref{table:#1}}
\newcommand{\fRef}[1]{Figure \ref{figure:#1}}
\newcommand{\sRef}[1]{Section \ref{section:#1}}
\newcommand{\eRef}[1]{Equation \ref{equation:#1}}

\newcommand{\fLabel}[1]{\label{figure:#1}}
\newcommand{\tLabel}[1]{\label{table:#1}}
\newcommand{\sLabel}[1]{\label{section:#1}}
% command for my captionc
% command for first paragraph
\newcommand{\firstp}[0]{}
% command for ending a paragraph
\newcommand{\pl}[0]{\vspace{6pt}}
\newcommand{\pEndF}[0]{ \\ }
\newcommand{\pStartF}[0]{ }

% single-spaced captions. see:
% tex.stackexchange.com/questions/153334/change-the-baselinestretch-line-spacing-only-for-figure-captions
\usepackage{graphicx,kantlipsum,setspace}
\usepackage{caption}
\captionsetup[table]{font={stretch=1}}    
\captionsetup[figure]{font={stretch=1}}


\newcommand{\pLit}[4]{
\cite{#1}
\begin{adjustwidth}{2.5em}{0pt}
\textbf{Title}: \citetitle{#1} \\
\textbf{Keywords}: #4 \\
\textbf{Big Picture}: #2 \\
\textbf{Summary}: #3 
\end{adjustwidth}
}
% see: tex.stackexchange.com/questions/48152/dynamic-signature-date-line
\newcommand{\titledate}[2][2in]{%
  \noindent%
  \begin{tabular}{@{}p{#1}@{}}
    \\ \hline \\[-.75\normalbaselineskip]
    #2
  \end{tabular} \hspace{1in}
  \begin{tabular}{@{}p{#1}@{}}
    \\ \hline \\[-.75\normalbaselineskip]
    Date
  \end{tabular}
}
\newcommand{\name}[0]{FEATHER}
\newcommand{\acronym}[0]{\textbf{F}orce \textbf{E}xtension \textbf{A}nalysis using a \textbf{T}estable \textbf{H}ypothesis for \textbf{E}vent \textbf{R}ecognition}
\newcommand{\TitleName}[0]{A Bayesian Algorithm for Detecting Molecular Unbinding Events in Force Spectroscopy Time Series Data}
\newcommand{\figwidth}[0]{\linewidth}
% supply: for 'citing' where we got a reagent or thing
%    Args:
%        #1: name of company we got the thing from
%        #2: product number for the thing
\newcommand{\supply}[2]{(#1 #2)}
% singlemol: for writing single molecular force spectroscopy
\newcommand{\singlemol}[0]{SMFS}
% degreeC: for abbreviating degrees celsius
\newcommand{\degreeC}[0]{\degree{}C}
% citePRH: for controlling the citation method
\newcommand{\citePRH}[1]{\cite{#1}}

\linespread{2.0}

\captionsetup[figure]{format=hang,justification=raggedright,indent=-22pt}
\captionsetup[table]{format=hang,justification=raggedright,indent=-31pt}
% make it so there arent terrible spaces everywehre
% see :
% tex.stackexchange.com/questions/36423/random-unwanted-space-between-paragraphs
\raggedbottom

% change the equations to not be so awful
%tex.stackexchange.com/questions/69662/how-to-globally-change-the-spacing-around-equations
\newcommand{\pSkip}[0]{0pt}
\makeatletter
\g@addto@macro\normalsize{%
  \setlength\abovedisplayskip{\pSkip}
  \setlength\belowdisplayskip{\pSkip}
  \setlength\abovedisplayshortskip{\pSkip}
  \setlength\belowdisplayshortskip{\pSkip}
}


\begin{document}

% single spaced
\singlespacing

% 'Items 1-8 in list are numbered with lower case Roman numerals.'
% see: http://tex.stackexchange.com/questions/7355/how-to-suppress-page-number
\pagenumbering{roman}

\title{\TitleName{}}
\author{
by \\
PATRICK RAYMOND HEENAN \\
B.A. Computer Science, University of North Carolina at Chapel Hill, 2013 \\
B.S. Physics, University of North Carolina at Chapel Hill, 2013 \\
\\
\\
\\
A thesis submitted to the Faculty of the Graduate School\\ 
of the University of Colorado in partial fulfillment of\\
the requirement for the degree of\\
Master of Science \\
Department of Computer Science\\
}
% XXX The title page contains the thesis title; candidate's name; candidate's degrees, granting institutions, and dates received; statement shown on sample page ("A thesis submitted to ..."); name of department or school granting degree; and year the thesis is submitted (see sample title page).


\maketitle
\thispagestyle{empty}


\clearpage

\section{Signature Page}

\begin{center}
This thesis entitled: \\
\TitleName \\
written by Patrick Raymond Heenan \\
has been approved for the Department of Computer Science \\
\end{center}

\leavevmode \newline

\begin{center}

\titledate{Rafael Frongillo}

\leavevmode \newline  \newline

\titledate{Jordan Boyd-Graber}

\leavevmode \newline  \newline

\titledate{Tom Perkins}

\leavevmode \newline \newline \newline 
The final copy of this thesis has been examined by the signatories, and we\\
find that both the content and the form meet acceptable presentation standards\\
of scholarly work in the above mentioned discipline.

\end{center}


\clearpage


\section{Abstract}

\noindent Heenan, Patrick Raymond (M.S., Computer Science) \newline
\hangindent=0.75cm \TitleName{} \par
\noindent Thesis directed by Associate Professor Rafael Frongillo \newline


\begin{abstract}
\firstp In a Single Molecule Force Spectroscopy (\singlemol{}) experiment, mechanical forces are applied to individual biomolecules via a force probe such as an optical trap or an atomic force microscope (AFM). In \singlemol{} unfolding experiments, the molecule of interest is pulled apart and force is measured as a function of probe position relative to a relaxed state. Although these unfolding experiments are capable of measuring a wide class of molecular phenomena, interpreting \singlemol{} data is hindered by identifying where unfolding events occur. This paper introduces a new algorithm, \name{} (\acronym), for identifying the locations of molecular unfolding events. Relative to two other event-detection algorithms on an annotated data set, \name{} features a median event localization error of 4nm, a 100-fold improvement, and a Bhattacharyya coefficient of 0.96, an improvement of 0.4, for the joint probability distribution of event loading rates and rupture forces. As a linear-time algorithm for reproducible event identification, \name{} improves the quality of analysis of \singlemol{} data.
\end{abstract}

\clearpage

\section{Dedication}

\clearpage

\section{Table of Contents Page}

\tableofcontents

\clearpage

\section{List of Tables Page}

\listoftables

\clearpage

\section{List of Figures Page}

\listoffigures
 
\clearpage

% 'Items 1-8 in list are numbered with lower case Roman numerals.'
% see: http://tex.stackexchange.com/questions/7355/how-to-suppress-page-number
\pagenumbering{arabic}

%\pacs{32.30.Rj, 32.50.+d, 32.70.Fw, 32.70.Jz}% PACS, the Physics and Astronomy
                             % Classification Scheme.
%\keywords{Review, x-ray fluorescence, scattering, attenuation}%Use showkeys class option if keyword
                              %display desired
\maketitle

\doublespacing

\section{\sLabel{Intro}Introduction}

\firstp Atomic force microscopy (AFM) is a powerful tool for studying the mechanical properties of biological molecules.  AFM can resolve sub-nanometer molecular structure such as the major and minor grooves of DNA \citePRH{ido_beyond_2013}, lattice structure of membrane-bound proteins \citePRH{muller_surface_1999}, and real-time motion of motor proteins\citePRH{ando_high-speed_2007}. As a force spectroscopy technique, AFM is capable of dynamic experiments including measuring the unfolding and refolding kinetics of single proteins\citePRH{he_direct_2015}, unzipping double-stranded DNA\citePRH{krautbauer_Unzipping_2003}, and unfolding and refolding pathways for membrane proteins (\citePRH{yu_hidden_2017}). The viability of AFM in a wide range of temperatures, solvents, and other environmental variables makes it attractive for studies of biological systems. \pl

During an AFM experiment, an atomically sharp tip attached to a cantilever interacts with a sample (\fRef{Cartoon}). The interaction is measured by the displacement of the tip via deflection of the cantilever. A calibrated tip can record interaction forces from piconewtons to nanonewtons. \pl

In single molecular force spectroscopy (\singlemol{}) experiments, the AFM tip attacheds to a molecule and stretches it to measure the relationship between force and extension over time. This experiment records the force-extension curve of the molecule (\fRef{Cartoon}). Force-extension curves yield information such as kinetic rates of processive enzymes \citePRH{comstock_direct_2015}, protein-ligand bond strength \citePRH{yuan_energy_2000}, and the energy landscapes of proteins and nucleic acids \citePRH{dudko_Theory_2008}. \pl

\begin{figure}
\centering
\includegraphics[width=\figwidth]{../Figures/Finals/cartoon.pdf}% Here is how to import EPS art
\caption[Diagram of AFM attachment geometry]{\fLabel{Cartoon}\pStartF Diagram of tip attachment geometry. (a1,a2) A diagram and force-extension curve corresponding to no attachments. (b1,b2) As previous, except illustrating a single attachment. (c1,c2) As previous, except illustrating multiple attachments. For all subplots, the force changes color at the location of a tagged event.  \pEndF }
\end{figure}


The analysis and interpretability of \singlemol{} experiments is limited by the attachment of the tip to the molecule of interest. Even with a high-concentration sample, quality \singlemol{} data between an attached molecule and commercially-available AFM tips occur less than one curve in tens of thousands\cite{bosshart_reference-free_2012}. Attachment rates are improved by coating the AFM tip with a molecule exhibiting high binding affinity for the sample of interest (cite Rob XXX), but the majority of the data taken is still uninterpretable and must be filtered out. Filtering data without events and identifying the locations of events within data is a major challenge in AFM data management and analysis.\pl

Methods exist to automate manually sorting \singlemol{} data and detect tip-sample events. Automation removes the burden of tedious data filtering and improves scientific reproducibility. Automation techniques include alignment and binning in contour-length space\cite{kuhn_automated_2005,bosshart_reference-free_2012}, thresholding based on signal and noise characteristics \cite{gergely_semi-automatized_2001,roduit_openfovea:_2012} or wavelet transformations \cite{garcia-masso_automated_2016,benitez_searching_2017}, and classification schemes \cite{kasas_fuzzy_2000}. These methods do provide an increased degree of autonomy, but their use is limited by their lack of generalization and interpretability. In particular, contour-length alignment algorithms bias results towards the dominant features and necessarily require a polymer model for the contour length as a function of force and extension. In applications interested in novel biomolecules or rare behavior of a biomolecule, alignment algorithms will have limited use.  On the other hand, thresholding and classification-based algorithms generally require optimizing many hard-to-interpret parameters. As we show below, these optimizations do not generalize well to the typical range of \singlemol{} data (\fRef{Performance}).\pl

This paper describes a new method based on machine learning for detecting events in \singlemol{} force-extension curves.  The algorithm, named \name{} (\acronym{}), require no \emph{a priori} knowledge of the polymer under study, does not bias interpretation of the data towards the dominant behavior of the data, and has a single, easy-to-interpret parameter which generalizes well to typical \singlemol{} data ranges. \name{} is so-named since it is designed to make few assumptions about the data, operate over a wide range of AFM data, and require a small time and memory footprint compared to existing techniques.\pl

 The first part of the paper describes the sample preparation, data acquisition, and data annotation needed to capture the unbinding of functionalized double-stranded DNA from functionalized AFM cantilevers (\fRef{Cartoon}). After, this research details manually annotating the unbinding events in the force-extension curves of the DNA at multiple pulling velocities, effective contour lengths, and events per curve (see \tRef{statistics}). Finally, the details and improved performance of \name{} are described. \pl

\section{\sLabel{Materials}Materials and Methods}

\subsection{Sample Preparation}

\firstp Site-specific chemistry is used to improve the acquisition rate and quality of data. The procedure for surface, sample, and cantilever preparation has been described elsewhere (CITE XXX Rob) and in \sRef{SampleDetails}. Briefly, through polymerase chain reaction, double-stranded DNA is functionalized with DBCO at one end to ensure a covalent bond with an azide-functionalized surface. The polymer is also functionalized with biotin at the opposite end to ensure a specific but reversible bond with a streptavidin-coated cantilever. These two bonds ensure the tip-polymer bond is broken before the surface-polymer bond, preventing tip contamination. \pl

\subsection{\sLabel{Surface}Atomic force microscopy}

\firstp All atomic force microscopy measurements were carried out using an Asylum Cypher \supply{Asylum Research}{Cypher ES}. The spring constant and sensitivity were determined using the equipartition theorem method (cite XXX). All measurements were carried out with a 2 second pause at the surface at the pulling velocities noted in the text. To reduce the effect of a possible non-uniform spatial distribution of the sample, measurements were taken at over a series of 25$\muup$m x 25$\muup$m grids at points separated by 1$\muup$m. The stage was translated to a new grid point after measuring three force-extension curves. \pl

\subsection{\sLabel{Annotation}Data annotation}


\begin{figure}
\centering
\includegraphics[width=\figwidth]{../Figures/Finals/ruptures.pdf}% Here is how to import EPS art
\caption[Definition of rupture force and loading rate]{\fLabel{Rupture} (a) A force extension curve with a shadow over an event. (b) The shadowed region of (a), with a linear fit of the data in region immediately proceeding the rupture region, which is shadowed. (c) The shadowed region from (b). The rupture point and rupture force are defined as the last data point above the linear fit in the fitting region. The loading rate is defined by the slope of the linear fit. For all subplots, the force changes color at the location of a tagged event. }
\end{figure}

\firstp Two hundred force-extension curves with events were obtained at three different pulling velocities (100nm/s,500nm/s,1000nm/s). The start and end of each event in a curve, as indices offset from the start of the curve, were obtained through manual annotation. The curves and the events were saved into comma-separated value files. \pl

The expected rupture forces and loading rates were calculated from the annotated data. This process is shown graphically in \fRef{Rupture}. The region leading up to the event start was fit by a line, with the region length set to 2\% of the number of points in the retract. The loading rate was assigned to the line's slope, and the rupture force was calculated by the value of the line at the time value where the data was last above the line. This is the same procedure used to calculate the loading rate and rupture force of predicted events in \fRef{Performance}. \pl



\subsection{\sLabel{Algorithm}Algorithm Design and Analysis}

All timing and tuning experiments were carried out on a desktop with 16GB of RAM, a 3.7GHz i7-4790 CPU, and a 1TB hard drive. \pl

\subsubsection{\sLabel{Metrics}Algorithm description}

\name{} improves on previous methods by using information present in the data collected during the approach of the AFM cantilever to the surface-bound molecules (\fRef{Cartoon}).  \fRef{Code} lists the psuedocode for the method. In summary, the algorithm calculates an upper bound on the probability of no event occuring at each time point, using parameters estimated from the approach portion of the curve (see \sRef{DesignDetails}). The probability at each point is then iteratively updated using Bayesian inference, in order to remove the effect of adhesions and other false-positives (see XXX). As shown in \fRef{FeatherExample}, the result is a probability at each time point which drops from one towards zero near events. A threshold probability is set by the user or optimized by a tuning routine (see \sRef{Tuning}). Contigous regions of time with probabilities below the threshold are considered having a single event, and the rupture location is determiend within each region by the method of \fRef{Rupture} and the relevant text.

\subsubsection{\sLabel{Metrics}Performance Metrics}

\firstp Three metrics were used for comparing the event-finding performance of \name{} with the human-annotated data. The metrics we report are listed in \tRef{metrics} with more details in \tRef{MetricParts}. The event error metrics, $f_{85}$ and $z_{85}$, describe how closely the predicted event locations align with the human-tagged data, and the rupture Bhattacharya coefficient, $\braket{d_{(\nu,F),t}^{\frac{1}{2}}|d_{(\nu,F),p}^{\frac{1}{2}}}$, reports the overlap between the expected and actual distribution over loading rates and rupture forces . \pl


\begin{table}
\begin{tabularx}{\textwidth}{ l | l | l | l  }
\hline \hline
Name & Notation  & Range & \text{Optimum} \e 
relative event error & f$_{85}$ &   [0,1] & 0 \e
absolute event error & z$_{85}$ & [0,max(x$_k$)] &  0 \e
rupture Bhattacharya coefficient (BC) & $\braket{d_{(\nu,F),t}^{\frac{1}{2}}|d_{(\nu,F),p}^{\frac{1}{2}}}$ & [0,1] & 1 \e
\end{tabularx}
\caption[Definition of algorithmic performance metrics]{\tLabel{metrics} The definitions of the performance metrics reported. All the symbols used are defined in \tRef{MetricParts}, with the exception of the rupture BC's bra-ket notation, representing an inner product between its arguments. }
\end{table}

\subsubsection{\sLabel{Compare}Choice of competing methods}

\firstp The following two algorithms were chosen for comparison to \name{}: \pl

\begin{enumerate}
\item The AFM-specific `event\_find' routine from the OpenFovea AFM analysis package.\cite{roduit_openfovea:_2012}
\item The general-purpose `find\_peaks\_cwt' method from the Scientific Python package.\cite{Jones_SciPy:_2001}
\end{enumerate}

 These methods were chosen to provide a representative sample of the viable techniques used in AFM data analysis. Unlike quadratic alignment algorithms in contour length space, these methods scale like O(N) and O(N$\cdot\log$(N)) respectively, where N is the length of a curve to be analyzed. Linear or near-linear scaling is desirable (see \fRef{Timing}) for analyzing hundreds of force-extension curves of hundreds of thousands of points each (see \tRef{statistics}). The baselines represent two common, distinct methods of event detection in AFM, since the OpenFovea method is a thresholding algorithm, and the Scientific Python method is a wavelet-based algorithm. \pl

\subsubsection{\sLabel{Tuning}Algorithm tuning}

\firstp All three algorithms were tuned using 5-fold cross validation. Cross validation was performed at fifteen log-spaced parameters over the useful parameter range of the algorithms (\fRef{Tuning}). The parameter value minimizing the total number of missing and extra events for an algorithm was considered the algorithm's best parameter. Data shown in the results consists of the concatenation of all validation folds for each algoritm's best parameter. \pl

Since tuning the baselines on the full dataset using our computer would have required more than eight cpu-months (compared to $\approx$1.5 cpu-days for \name{}, see \fRef{Timing}), a smaller subset of data was used for comparing the algorithms. In particular, the subset of the data with the smallest number of points per curve \textemdash{} 200 curves with v=1000nm/s, N$\approx1\times10^{5}$ (see \tRef{statistics}) \textemdash{} was used for results comparing \name{} to the baselines. \name{} was also tuned separately on the larger, more complex dataset, with similar results to those reported in the rest of the paper (\fRef{LargeDataset}). This demonstrates that \name{} generalizes well to large data sets and a wide range of loading rates. 

\section{\sLabel{Results}Results}

\subsection{\sLabel{Timing}Algorithmic time complexity}

\firstp \fRef{Timing} compares the runtimes, T(n), of \name{} and the baselines. As expected, the runtime of each algorithm is roughly linear for in the region of interest, with \name{} having roughly tendold better asymptotic slopes.  \pl

\begin{figure}
\centering
\includegraphics[width=\figwidth]{../Figures/Finals/timing.pdf}% Here is how to import EPS art
\caption[Runtime versus length of curve]{\noindent\fLabel{Timing}\pStartF  Big-O runtime of each algorithm is approximately linear. (a) The runtime per curve versus number of points in the curve, T(N), for each algorithm is plotted as points. Lines around the data show the best-fit upper and lower bounds of the form T$_{\mathrm{upper}}$(n) = a$_0$ + 2a$_1$n  and T$_{\mathrm{lower}}$(n) = a$_0$ + $\frac{1}{2}$a$_1$n. (b) The linear constants $a_1$, representing the asymptotic runtime per data point, for each algorithm from (a) are plotted. \pEndF}
\end{figure}

\subsection{\sLabel{Performance}Algorithmic event detection performance}

\fRef{Performance} shows the event-detection performance of \name{} and the baseline algorthms. As defined by \tRef{metrics}, relative to the best baseline \name{} improves the relative and absolute event error by a factor of 100 and almost doubles the Bhattacharya coefficient over the spectrum of loading rates and rupture forces. 

\begin{table}
\begin{tabularx}{\textwidth}{ l || l | l | l }
\hline \hline
 & Rupture BC ($\uparrow$) & Absolute event error [nm]($\downarrow$) & Relative event error ($\downarrow$)\e\hline 
no event & \textbf{0.96} & \textbf{9.42} & \textbf{0.0054}\e
open fovea & 0.354 & 951 & 0.57\e
wavelet transform & 0.556 & 1.77e+03 & 1\e
\end{tabularx}
\caption[Algorithm performance]{\tLabel{AppliedMetrics} Performance metrics across the three algorithms. The optimal algorithm row for each metric is highlighted in bold, depending on if the metric optimum is low (denoted by a $\downarrow$ next to the name) or high (denoted by a $\uparrow$ next to the name).} 
\end{table}




\begin{figure}
\centering
\includegraphics[width=\figwidth]{../Figures/Finals/landscape.pdf}% Here is how to import EPS art
\caption[Algorithm Performance]{\noindent\fLabel{Performance}\pStartF Performance of this algorithm compared to the baseline algorithms. (a1) The distributions of distances from predicted to true points d$_{\mathrm{p}\rightarrow\mathrm{t}}$ and from true to predicted points, d$_{\mathrm{t}\rightarrow\mathrm{p}}$ for \name{}. (a2) \name{}'s two-dimensional distribution of predicted and actual rupture force and loading rate, as defined in \fRef{Rupture}. (a3 and a4) The histograms of rupture forces and loading rates, respectively, for \name{}.  (a5) The metrics defined in \tRef{metrics}. (b1-b5): As a1-a5, but for OpenFovea. (c1-c5): As a1-a5, but for the Scientific Python basline \pEndF }
\end{figure}



\section{\sLabel{Discussion}Discussion}


\firstp \pl \name{} provides order-of-magnitude improvements in both speed and physically-relevant metrics for algorithm performance, relative to the baselines presented. As shown in \fRef{LargeDataset}, \name{} also generalizes well to more complex \singlemol{} data.  \pl

This work applied \name{} to unfolding in \singlemol{} data, but the algorithm could be generalized to a wider array of applications. Changing \name{} to search for refolding events in \singlemol{} data is a natural and useful generalization. In addition, domain-specific models could be combined with \name{} to further filter data, based on the specific experiment. For example, if an experimenter was attempting to measure the force-extension relationship of a DNA hairpin of contour length 100nm, she could first obtain all rupture locations in her data via \name{}, fit a polymer model to the data to obtain the contour length, then remove all data with contour lengths outside of (100$\pm \epsilon$)nm, where $\epsilon$ is a small number. By predicting where events occur without providing any domain-specific model of the event, \name{} is one tool in a longer \singlemol{} analysis pipeline.

\name{} could be used in different scientific domains than \singlemol{}. To reduce the risk of overfitting to a specific tipe of \singlemol{} experiment, \name{} purposefully makes no assumptions about domain-specific data models (e.g. a polymer model for the force-extension relationship of DNA). \singlemol{} data is a natural application for \name{}, since each retract curve, with its scientifically interesting data, is paired with an approach curve which is assumed lacking any events. The approach gives approximations to the parameters needed to estimate \name{}'s probability bound. In domains which can estimate \name{}'s parameters (\fRef{FeatherExample}) and endeavor to localize events defined by discontinuous derivatives in otherwise continuous time series data (as shown in \fRef{Cartoon}), \name{} could be leveraged to improve scientific reproducibility.

\clearpage

\section{References}



\clearpage

\section{Bibliography}

\bibliography{Masters}


\clearpage

\section{Appendix}

%restarct numbering for appendix
\renewcommand{\thepage}{S\arabic{page}} 
\renewcommand{\thesection}{S\arabic{section}}  
\renewcommand{\thetable}{S\arabic{table}}  
\renewcommand{\thefigure}{S\arabic{figure}} 
\setcounter{figure}{0}
\setcounter{table}{0}


\subsection{\sLabel{SampleDetails}Sample and Cantilever Preparation}


\begin{table}
\begin{tabularx}{\textwidth}{ l | l  }
\hline \hline
Forward primer & Dagttgttcctttctattctcactccgc \\ \e 
Reverse primer & BtcaataaTcggctgtctTtccttatcaTtc \\ \e 
\end{tabularx}
\caption[DNA primer sequences]{\tLabel{Sequences}Sequences for single-stranded DNA construct and for double-stranded DNA primers. The forward and reverse primers amplify a 647nm piece of DNA, from positions 1607 to 3520 on the M13mp18 plasmid, as discussed in the next. Unmodified DNA bases are lowercase. The uppercase letters `T',`B', and `D' respectively represent biotinylated Thymidine residues, a terminal Biotin separated from the sequence by triethyleneglycol spacer, and a terminal Dibenzocyclooctyl separated from the sequence by triethyleneglycol spacer.}
\end{table}


\subsubsection{\sLabel{Surface}Azide-functionalied surfaces}

\firstp Glass surfaces were smoothed using Potassium Hydroxide etching as follows. 12mm diameter glass disks \supply{Ted Pella}{26023} were sonicated \supply{Branson}{2510} for 5 minutes in 250mL of 95\% ethanol \supply{Decon}{2801}, sonicated  for 5 minutes in 250mL of ACS grade acetone \supply{Fisher}{A18-4}, and transferred to a solution of 80g of Potassium Hydroxide \supply{Fisher}{P250-500} dissolved in  170mL of 65\% ethanol and 80mL of deionized water \supply{Barnstead}{GenPure Pro} for 3 minutes. To removed residual KOH, the glass was serially diluted in two 1L beakers of 18.2M$\Omega$ deionized water. The etched surfaces were dried with 99.8\% pure Nitrogen gas \supply{Airgas}{NI UHP-300} and stored at room temperature in a dust-proof box. \pl

To create azide-functionalized surfaces, etched glass was activated using 30 minutes exposure in a UV-ozone chamber \supply{Novascan}{PSDP Digital UV Ozone System} and incubated for three hours in a 70mL, 60\degreeC{} solution of 0.15mg/mL 600Dalton Silane-PEG-Azide \supply{Nanocs}{PG2-AZSL-600} dissolved in toluene \supply{Sigma}{179418-4L}. The surfaces were then mounted in a custom-made teflon-holder and rinsed serially in 250mL of toluene, isopropanol \supply{Fisher}{A416-4}, and deionized water. The azide-functionalized surfaces were dried with Nitrogen gas and stored in a dust-proof container at 4\degreeC{}. \pl 

\subsubsection{\sLabel{Sample}DNA Samples}

\firstp For the 1914bp double-stranded DNA, the 1607 forward-sense and 3520 reverse-sense primers (\tRef{Sequences}) for the M13mp18 plasmid \supply{New England BioLabs}{N4018S} were obtained from Integrated DNA Technologies  and used for polymerase-chain reaction \supply{Millipore}{71086-4} using 40 cycles on a thermocycler \supply{Bio-Rad}{T100}. The reverse-sense primer was modified to include three biotinylated thyimine bases and a 5-prime biotin after a PEG spacer, and the forward-sense primer was modified to include a 5-prime DBCO after a PEG-spacer (see \tRef{Sequences}). After the PCR product was purified \supply{Qiagen}{28106} and the 1.9kbp band selected by 2\% gel electrophoresis \supply{Sigma}{A9539-500}, the agarose was eluted out \supply{Bio-Rad}{732-6165}, the DNA solution was concentrated \supply{Millipore}{UFC501096}, purified \supply{Qiagen}{28106}, and stored at 4\degreeC{} in a solution of TE, 10mM Tris \supply{Fisher}{BP151-1} and 1mM EDTA \supply{Fisher}{S311-500} at pH 8.0. The typical recovery efficiency of this procedure was 25\%. \pl

The purity of the DNA was verified by depositing 20pmol of DNA in imaging buffer, 3mM Nickel \supply{Sigma}{654597}, 10mM Hepes \supply{Sigma}{H4034} at pH 7, onto freshly-cleaved, 10mm diameter, V1 mica \supply{Ted Pella}{50} for 10 minutes, rinsing serially 5 times with 1mL of deionized water and 5 times with imaging buffer. The sample was then imaged with Cypher using a cantilever with a spring constant of $\approx 300 \frac{\text{pN}}{\text{nm}}$ \supply{Bruker}{SNL-10} with a line scan rate of 1Hz and free amplitude of $\approx$1nm (\fRef{Prep}).\pl 

For DNA deposition onto azide surface, 20uL of the DNA at 40nM was mixed with 80uL of TE at pH 8.0 and deposited onto azide-functionalized glass (see \sRef{Surface}) affixed with epoxy \supply{Devcon}{14250} to specimen disks \supply{Ted Pella}{16218} and incubated at 4C for 15 hours. The surfaces were rinsed by 7mL of TE at pH 8.0 and 7mL of PBS with 1mM EDTA at pH 7.4, and stored at 4\degreeC{}. 

\subsubsection{\sLabel{Cantilevers}Streptravidin-functionalized cantilevers}

\firstp Functionalized cantilevers with nominal spring constants of 4 $\frac{\text{pN}}{nm}$  were used for all experiments. Functionalization etches away gold to improve force stability (XXX cite) and covalently attaches streptatividin to the etched cantilevers to improve attachment to the biotinylated DNA. Commercially available cantilevers \supply{Asylum Research}{BL-RC-150VB} were serially rinsed for 30 seconds in 50mL of gold etchant \supply{Transene}{TFA}, 250mL of deionized water, 50mL of chromium etchant \supply{Transene}{1020}, 250mL of deionized water, and one final rinse in 250mL of deionized water. After drying, the tips were activated using 30 minutes exposure in a UV-Ozone chamber and incubated for three hours in a 70mL, 60\degreeC{} solution of 0.15mg/mL 600Dalton Silane-PEG-Maleimide \supply{Nanocs}{PG2-MLSL-600} dissolved in toluene. The maleimide-functionalized tips were serially rinsed in 50mL of toluene, isopropanol, water, immediately dried \supply{KimTech}{5511}, and immersed for three hours in a 0.4mg/mL solution of thiol-streptavidin \supply{Protein Mods}{SAVT} in PBS \supply{Millipore}{524650} at pH 6.75 with 1mM TCEP \supply{Thermo Scientific}{77720} at room temperature in a moisture-proof container. The tips were then tranferred to 4\degreeC{} for 15 hours. After the 4\degreeC{} incubation, to remove free streptavidin, the tips were serially rinsed in two 10mL beakers of PBS at pH 7.4 and submerged in a 20mL petri dish of PBS for 10 minutes. The tips were then stored in 50$\muup$L of PBS at 4C in plastic wafers \supply{Entegris}{H22-10/1-0615} until loading into the atomic force microscope. \pl


\begin{table}
\begin{tabularx}{\textwidth}{ l | l | l | l |l |l|l|l }
\hline \hline
v [nm/s] & N$_\mathrm{curves}$ & $\mu_{\mathrm{Curve Size}}$ & $\sigma_{\mathrm{Curve Size}}$ & N$_{\mathrm{e}= 1}$ & N$_{\mathrm{e}= 2}$ & N$_{\mathrm{e}= 3}$ & N$_{\mathrm{e}\ge4}$  \\ \hline
100 & 200 & 667000 & 47000 & 159 & 33 & 5 & 3  \\ \hline
500 & 200 & 200000 & 1000 & 140 & 40 & 8 & 12  \\ \hline
1000 & 200 & 117000 & 7000 & 174 & 25 & 1 & 0  \\ \hline
\end{tabularx}
\caption[Data set statistical information]{\tLabel{statistics} For each loading rate v in the data set, this table lists the number of curves N$_{\mathrm{curves}}$; mean and standard deivaiton of curve sizes, $\mu_{\mathrm{Curve Size}}$ and $\sigma_{\mathrm{Curve Size}}$, in data ponts; the number of curves with `x' events N$_{\mathrm{e=x}}$ for x$\in\{1,2,3\}$; and the number of curves with greater than or equal to 4 events, $N_{\mathrm{e}\ge4}$. }
\end{table}



\subsection{\sLabel{DesignDetails} Algorithm Design}

This section details the mathematics and choices behind the event-detection algorithm. The following conventions are followed:

\begin{enumerate}
 \item All variables with uppercase letters are random variables.
 \item All variables with lowercase letters are either instances of the corresponding uppercase random variables (i.e., measurements) or pure functions.
 \item All variables with a hat (e.g. $\hat{\epsilon}_t$) are empirical measurements or estimated of an already-defined variable .
\end{enumerate}

\subsubsection{Defining the no-event hypothesis}

\firstp We define an event as when the time derivative of force applied to a molecule exhibits a discontinuity as the molecule passes over a free-energy barrier. We assume this event takes place on timescales much smaller than the response time of the probe. If this is not true, the data assumed smoothed until this condition is reached. The algorithm models the data assuming no event is occurring at a given time `t' and finds where the probability of a measurement is low. Hereafter, the definition of an event and the assumptions of no event at a given time will be referred to as the \emph{no-event hypothesis}. 

\subsubsection{Mathematical background for testing the no-event hypothesis}

\firstp Under the no-event hypothesis, the noise-dependent distribution of force `F' for a discrete series of forces sampled at points t can be well-approximated by the sum of a smooth signal and an noise distribution (\fRef{FeatherExample}):

\eqs{ F_t = g_t + X(0,\sigma^2) }

where `g$_t$' is a smooth function with a continuous first derivative and `X' is a random variable with zero mean and variance $\sigma^2$. The closed form of the smooth signal and the noise distribution are assumed unknown and can vary from one force extension curve to the next. If `$g^{*}_t$' is a function with a continuous first derivative approximately equal to $g_t$ such that $\forall t,\epsilon_t\equiv|g^{*}_t-g_t|$ for real $\epsilon_t\ge 0$, then we define an error distribution $R_t$ such that: \pl

\eqs{ R_t \equiv F_t - g^{*}_t = \epsilon_t + X(0,\sigma) }

where

\eqlab{ E[R_t^2] -E[R_t]^2 = [(g_t-g^{*}_t)^2 + E[X(0,\sigma)^2]] - (g_t-g^{*}_t)^2  = \sigma^2 }{feather-sigma}

and 

\eqlab{ |E[R_t]| = \epsilon_t \le E[|R_t|] }{feather-epsilon}

In practice (see \fRef{FeatherExample}), we approximate $\epsilon_t$ by the average over all time points $\hat{\epsilon}_t \approx \langle \epsilon_t \rangle_{\text{all t}} = \frac{1}{N} \sum_{t=1}^N |r_t|$. Under this assumption, the probability `P' of measuring $r_t$ is bounded by Chebyshev's inequality is:

\eqlab{ P( |R_t-\epsilon_t| \ge r_t-\epsilon_t ) \le
 (\frac{\sigma}{r_t-\epsilon_t})^2 }{feather-probability}


For \emph{any} noise distribution, this bounds the probability of a measurement under the no-event hypothesis, given the force approximation $g^{*}_t$ (which in turn yields the estimator error $\hat{\epsilon}$ and the noise $\hat{\sigma}$ by \eRef{feather-epsilon} and \eRef{feather-sigma}). A low probability at a given time implies the measurement is unlikely under the no-event hypothesis. \pl

\subsubsection{Accurate estimators for hypothesis testing}

XXX auto correlation time motivation \pl 

The approximation to the noiseless force $g^{*}_t$ is obtained by fitting a least-squares second-order basis spline (b-spline, ) to the force versus time curve. The spline is second-order to ensure a continuous first derivative (\fRef{FeatherExample}), and the spline knots are spaced uniformly at intervals of $\tau$. \fRef{FeatherExample} is a representative demonstration of the spline fitting. Determining  $g^{*}_t$ immediately gives $\hat{r}_t$ by  \eRef{feather-sigma}, \eRef{feather-epsilon}, and \eRef{feather-probability}. \pl

Using $r_t$ as shown in \eRef{feather-epsilon} does not provide a strong signal in the presence of an event (see \fRef{FeatherExample}). In order to improve the method, the distribution of windowed standard deviations `$s_t$' of $r_t$ centered at t with a window of $[-\frac{\tau}{2},\frac{\tau}{2}]$ was used in place of $r_t$. Using $s_t$ instead of $r_t$ provides a much stronger signal in the presence of an event (see \fRef{FeatherExample}).  \pl

The noise variables $\sigma$ and $\epsilon$ are estimated from the distribution of standard deviations $s_t$ on the region of the approach curve without the surface hard-contact. From this distribution, $\hat{\sigma}$ is set to the standard deviation of $s_t$, and $\hat{\epsilon}$ is approximated by the median. The median is used instead of the mean in order to remove the influence of possible false-positive events in the approach due to stage noise. The removal of these psuedo-events is necessary to ensure accurate estimations for $\sigma$ and $\epsilon$, which are based on the no-event hypothesis.


\begin{figure}
\centering
\includegraphics[width=\figwidth]{../Figures/Finals/algorithm.pdf}% Here is how to import EPS art
\caption[\name{} algorithmic pipeline]{\noindent\fLabel{FeatherExample}\pStartF Demonstrating how \name{} works. (a,b) The approach and retract forces versus time, with spline fits overlayed. (c,d) The approach and retract r$_t$ versus time, with s$_t$ overlayed, demonstrating the signa-to-noise benefit of using s$_t$. (e,f) The approach and retract s$_t$, with the estimates of $\epsilon$ and $\sigma$ from the approach overlayed. (g) The probability of no event at each time has a sharp minima near the expected event location. For all subplots, the retract changes color at the location of a tagged event. \pEndF }
\end{figure}


\subsubsection{Algorithm psuedocode}

\begin{figure}
  \begin{lstlisting}[language=Python]
def event_indices(force,threshhold):
   autocorrelation = [0,1] normalized autocorrelation of force
   med = median of autocorrelation
   autocorrelation_small_t = autocorrelation until reaching med
   $\tau$ = slope from line fit to log of autocorrelation_small_t
   N = number of points in force
   grid = array of points each spaced $\tau$ apart
   g$^{*}$ = second-order spline fit to force using grid for knots
   r = force - g$^{*}$
   n = number of points in force
   s[i] = standard deviation of r[max(0,i-$\tau$/2):min(i+$\tau$/2,n)]
   $\epsilon$ = median of s
   $\sigma$ = standard deviation of s within its interquartile region
   k = (s-$\epsilon$)/$\sigma$
   chebyshev = max(1,1/k$^2$)
   possible_events = indices where chebyshev <= threshhold
   return possible_events
\end{lstlisting}
\caption[\name{} psuedocode]{\noindent\fLabel{Code}\pStartF The psuedocode of \name{}. XXX fix\pEndF }
\end{figure}


\subsubsection{Performance Metrics}

For the performance metrics, we define the following, where `k' is one of the K total force-extension curves and `i' and `j' represent either true (t) or predicted (p): 



\begin{table}
\begin{tabularx}{\textwidth}{ l | l  }
Name & Definition \\ \hline \hline
$x_k$ & \text{the total displacement of the force extension curve} \\ \hline 
$d_{i\rightarrow j,k}$ & \text{ distribution of distances in `k' from `i' ruptures to the closest `j' ruptures in or $x_k$ if none } \\\hline 
$f_{\text{x}}$ &  \text{ the `x'-th percentile of the concatenation of } $\frac{1}{x_k}d_{t\rightarrow p,k}$ \text{ and } $\frac{1}{x_k}d_{p\rightarrow t,k}$ \text{ over all k } \\ \hline 
$z_{\text{x}}$ & \text{ as f$_{\text{x}}$, but without dividing by $x_k$}\\\hline 
$\nu_i$ & \text{ distribution of `i' loading rates over all k} \\\hline 
$F_i$ & \text{ distribution of `i' rupture forces over all k} \\\hline 
$d_{(\nu,F),i}$ & \text{ joint probability distribution of $\nu_i$ and $F_i$ over all k} \\\hline 
\end{tabularx}
\caption[Data set statistical information]{\tLabel{MetricParts}  }
\end{table}


For example, $d_{t\rightarrow p,4}$ represents the distances from the true to the predicted events in force-extension curve 4, $\nu_t$ represents the distribution of true ruptures forces over all curves, and $d_{(\nu,F),p}$ represents the 2-d distribution of predicted points in the space of loading rates and rupture forces. \pl


\begin{figure}
\centering
\includegraphics[width=\figwidth]{../Figures/Finals/feather_full_set.pdf}% Here is how to import EPS art
\caption[Performance of \name{} on larger data set]{\noindent\fLabel{LargeDataset}\pStartF This figure is identical to \fRef{Performance}, except it details the performance of only \name{} on the full data set listed in \tRef{statistics}, instead of merely the highest loading rate.  \pEndF }
\end{figure}

\subsubsection{Improvements}

XXX figure out how to determine where the adhesion ends, how to improve SNR by derivative stuffs.


\begin{figure}
\centering
\includegraphics[width=\figwidth]{../Figures/Finals/prep.pdf}% Here is how to import EPS art
\caption[Verification of sample purity]{\noindent\fLabel{Prep}\pStartF Purity of the sample preparation. (a) A 2\% electrophoretic agarose gel, showing a maor band at just below 2kbp, as expected. (b) A false-color AFM image of the DNA bound to mica. \pEndF }
\end{figure}


\begin{figure}
\centering
\includegraphics[width=\figwidth]{../Figures/Finals/tuning.pdf}% Here is how to import EPS art
\caption[Cross validation of algorithms and optimal parameters]{\noindent\fLabel{Tuning}\pStartF Details of tuning experiments. (a) The total number of extra and missing predicted events divided by the expected number of events for \name{}. (b) As (a), but for the Open Fovea method. (c) As (a), but for the Scientific Python method; \pEndF }
\end{figure}



\begin{figure}
\centering
\includegraphics[width=\figwidth]{../Figures/Finals/supplemental.pdf}% Here is how to import EPS art
\caption[Algorithmic runtime versus loading rate]{\noindent\fLabel{Timing_Details}\pStartF The runtime of the three methods versus loading rate and number of points. (a) \name{}'s total runtime versus number of curves analyzed for the curve sizes, N, listed. (b) The runtime per curve versus number of points, N. The runtimes at each N are obtained by the slope of the relevant line in (a).  (c,d) As (a,b), but for the Open Fovea method. (e,f) As (a,b), but for the Scientific Python method. \pEndF }
\end{figure}



\end{document}

%
% XXX difference wrt to solids. Auger, no space? \\

%

%
% ****** End of file aipsamp.tex ******
