% ****** Start of file aipsamp.tex ******
%
%   This file is part of the AIP files in the AIP distribution for REVTeX 4.
%   Version 4.1 of REVTeX, October 2009
%
%   Copyright (c) 2009 American Institute of Physics.
%
%   See the AIP README file for restrictions and more information.
%
% TeX'ing this file requires that you have AMS-LaTeX 2.0 installed
% as well as the rest of the prerequisites for REVTeX 4.1
%
% It also requires running BibTeX. The commands are as follows:
%
%  1)  latex  aipsamp
%  2)  bibtex aipsamp
%  3)  latex  aipsamp
%  4)  latex  aipsamp
%
% Use this file as a source of example code for your aip document.
% Use the file aiptemplate.tex as a template for your document.
\documentclass[%
  aip,12pt,tightenlines,
  amsthm,
 amsmath,amssymb
]{article}
\usepackage{braket}
% use utf-8 for  the input encoding (so the bibliography isnt terrible)
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
% allow for break spaces...
% defines \textmu, which is now what inputenx seems to use for μ - probably due inpmath.. also \textdegree... but not \textrho. Need utf - BOM
\usepackage{textcomp} 
\usepackage{textgreek}
\usepackage[greek,english]{babel}
% lstlisting: for code
\usepackage{listings}
% lstset: for stting colors of stuff
\lstset{language=python,mathescape,
  frame = single,
  basicstyle=\ttfamily,
  keywordstyle=\color{blue}\ttfamily,
  stringstyle=\color{red}\ttfamily,
  commentstyle=\color{green}\ttfamily}
\usepackage{dcolumn}% Align table columns on decimal point
\usepackage{bm}% bold math
% amsmath: for align, etc
\usepackage{amsmath}
%\usepackage[mathlines]{lineno}% Enable numbering of text and display math
%\linenumbers\relax % Commence numbering lines
\usepackage{txfonts}
% use natbib / superscripts
\usepackage[super]{natbib}
\bibliographystyle{unsrtnat}
\usepackage{tabularx}
% hyperref: enable clicking on citations
\usepackage{hyperref}
\usepackage{titlesec}
% gensymb: for degree
\usepackage{gensymb}
% use times new roman
% http://tex.stackexchange.com/questions/153168/how-to-set-document-font-to-times-new-roman-by-command
\usepackage{times}
% 'Thesis margins should be 1 inch from all edges.'
% 1 inch margins
% http://kb.mit.edu/confluence/pages/viewpage.action?pageId=3907057
\usepackage[margin=1in]{geometry}
\usepackage{graphicx}% Include figure files
% reducing heading madness
% http://tex.stackexchange.com/questions/53338/reducing-spacing-after-headings
\newcommand{\captionspacing}[0]{4pt plus 2pt minus 2pt}
\titlespacing\section{0pt}{\captionspacing}{\captionspacing}
\titlespacing\subsection{0pt}{\captionspacing}{\captionspacing}
\titlespacing\subsubsection{0pt}{\captionspacing}{\captionspacing}

% put the page number on the right handside
% http://tex.stackexchange.com/questions/56316/top-right-side-page-numbering
\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhf{}
\fancyhead[R]{\thepage}
% indent *all* paragraphs, not just after first
% "The first line of paragraphs or footnotes is indented uniformly in the 
% thesis.''
\usepackage{indentfirst}

\newcommand{\ndiffn}[3]{\frac{\partial^{#3}#1}{\partial^{#3}#2}}
\newcommand{\diffn}[2]{\ndiffn{#1}{#2}{}}
\newcommand{\eqs}[1]{
\begin{align*} 
\begin{split}
#1
\end{split}					
\end{align*}}

\newcommand{\pFig}[3]{
\begin{figure}[h!]
\centering
\pcaption{#2}
\boxed{\includegraphics[width=0.75\textwidth]{#1}}
\label{figure:#3}
\end{figure}}



\newcommand{\eqlab}[2]{
\begin{equation}
\label{equation:#2}
\begin{split}
#1
\end{split}
\end{equation}
}


\newcommand{\brac}[1]
{
  \Big[ #1 \Big]
}

\newcommand{\tab}[2]
{
\begin{tabular}[h!]{#1}
\hline
#2
\end{tabular}
}

\newcommand{\e}[0]{\\ \hline}

\newcommand{\pMat}[1]{
 \left[ \begin{array}
#1 \end{array} \right]
}

% for making specific references.
\newcommand{\tRef}[1]{Table \ref{table:#1}}
\newcommand{\fRef}[1]{Figure \ref{figure:#1}}
\newcommand{\sRef}[1]{Section \ref{section:#1}}
\newcommand{\eRef}[1]{Equation \ref{equation:#1}}

\newcommand{\fLabel}[1]{\label{figure:#1}}
\newcommand{\tLabel}[1]{\label{table:#1}}
\newcommand{\sLabel}[1]{\label{section:#1}}
% command for my captionc
% command for first paragraph
\newcommand{\firstp}[0]{}
% command for ending a paragraph
\newcommand{\pl}[0]{\vspace{6pt}}
\newcommand{\pEndF}[0]{ \\ }
\newcommand{\pStartF}[0]{ }

% single-spaced captions. see:
% tex.stackexchange.com/questions/153334/change-the-baselinestretch-line-spacing-only-for-figure-captions
\usepackage{graphicx,kantlipsum,setspace}
\usepackage{caption}
\captionsetup[table]{font={stretch=1}}    
\captionsetup[figure]{font={stretch=1}}


\newcommand{\pLit}[4]{
\cite{#1}
\begin{adjustwidth}{2.5em}{0pt}
\textbf{Title}: \citetitle{#1} \\
\textbf{Keywords}: #4 \\
\textbf{Big Picture}: #2 \\
\textbf{Summary}: #3 
\end{adjustwidth}
}

\newcommand{\name}[0]{Feather}
\newcommand{\figwidth}[0]{\linewidth}
% supply: for 'citing' where we got a reagent or thing
%    Args:
%        #1: name of company we got the thing from
%        #2: product number for the thing
\newcommand{\supply}[2]{(#1 #2)}
% singlemol: for writing single molecular force spectroscopy
\newcommand{\singlemol}[0]{SMFS}
% degreeC: for abbreviating degrees celsius
\newcommand{\degreeC}[0]{\degree{}C}
% citePRH: for controlling the citation method
\newcommand{\citePRH}[1]{\cite{#1}}

\linespread{2.0}

\captionsetup[figure]{format=hang,justification=raggedright,indent=-22pt}
\captionsetup[table]{format=hang,justification=raggedright,indent=-31pt}
% make it so there arent terrible spaces everywehre
% see :
% tex.stackexchange.com/questions/36423/random-unwanted-space-between-paragraphs
\raggedbottom

% change the equations to not be so awful
%tex.stackexchange.com/questions/69662/how-to-globally-change-the-spacing-around-equations
\newcommand{\pSkip}[0]{0pt}
\makeatletter
\g@addto@macro\normalsize{%
  \setlength\abovedisplayskip{\pSkip}
  \setlength\belowdisplayskip{\pSkip}
  \setlength\abovedisplayshortskip{\pSkip}
  \setlength\belowdisplayshortskip{\pSkip}
}


\begin{document}

% single spaced
\singlespacing

% 'Items 1-8 in list are numbered with lower case Roman numerals.'
% see: http://tex.stackexchange.com/questions/7355/how-to-suppress-page-number
\pagenumbering{roman}

\title{A Bayesian Algorithm for Detecting Molecular Unbinding Events in Force Spectroscopy Time Series Data}
\date{\today}
\author{Patrick Heenan XXX The title page contains the thesis title; candidate's name; candidate's degrees, granting institutions, and dates received; statement shown on sample page ("A thesis submitted to ..."); name of department or school granting degree; and year the thesis is submitted (see sample title page).
 \\  University of Colorado at Boulder }

\maketitle
\thispagestyle{empty}


\clearpage

Signature Page

\clearpage

Abstract

\begin{abstract}

\firstp Non-destructive methods for identifying elemental makeup provide valuable insight for researchers investigating object composition. X-ray fluorescence (XRF) has emerged as an \emph{in situ} method to obtain the elemental makeup of objects, including sub-surface composition. For example, XRF can reconstruct “hidden” paintings beneath a surface image, resolve disputed claims of authorship, and recover text from partially effaced religious documents. XRF traditionally uses synchrotron radiation as a light source and raster scans the artifact of interest. The pixels from the scan are combined into a coherent picture after days of imaging. Recent work focuses on creating two-dimensional images of the artifact's sub-surface elemental composition in hours or days by digitizing photon counts onto a charged coupled device camera. The number of photons in each energy bin for each pixel, constituting the scattered and fluorescent light from the object, are converted into element concentrations by comparing the photon intensities with a prior calibration and correcting for instrumental artifacts and background. This work describes the physical theory, optical instrumentation, and data analysis underpinning recent advances in spatial and temporal resolution in sub-surface reconstruction using XRF. 
\end{abstract}

\clearpage

Dedication

\clearpage

Acknowledgements

\clearpage

Contents

\tableofcontents

\clearpage

List of Tables 

\listoftables


\clearpage

List of Figures 

 
\listoffigures
 

\clearpage

Text

% 'Items 1-8 in list are numbered with lower case Roman numerals.'
% see: http://tex.stackexchange.com/questions/7355/how-to-suppress-page-number
\pagenumbering{arabic}

%\pacs{32.30.Rj, 32.50.+d, 32.70.Fw, 32.70.Jz}% PACS, the Physics and Astronomy
                             % Classification Scheme.
%\keywords{Review, x-ray fluorescence, scattering, attenuation}%Use showkeys class option if keyword
                              %display desired
\maketitle

\doublespacing

\section{\sLabel{Intro}Introduction}

\firstp Atomic force microscopy (AFM) is a powerful tool for studying the mechanical properties of biological molecules.  AFM can resolve sub-nanometer molecular structure such as the major and minor grooves of DNA \citePRH{ido_beyond_2013}, lattice structure of membrane-bound proteins \citePRH{muller_surface_1999}, and real-time motion of motor proteins\citePRH{ando_high-speed_2007}. As a force spectroscopy technique, AFM is capable of dynamic experiments including measuring the unfolding and refolding kinetics of single proteins\citePRH{he_direct_2015}, unzipping double-stranded DNA\citePRH{krautbauer_Unzipping_2003}, and unfolding and refolding pathways for membrane proteins (XXX Hao/Matt). The viability of AFM in a wide range of temperatures, solvents, and other environmental variables makes it attractive for studies of biological systems. \pl

During an AFM experiment, an atomically sharp tip attached to a cantilever interacts with a sample(\fRef{Cartoon}). The interaction is measured by the displacement of the tip via deflection of the cantilever. A calibrated tip can record interaction forces from piconewtons to nanonewtons. \pl

In single molecular force spectroscopy (\singlemol{}) experiments, the AFM tip interacts with a molecule and stretches it to measure the relationship between force and extension over time. This experiment records the force-extension curve of the molecule (\fRef{Cartoon}). Force-extension curves yield information such as kinetic rates of processive enzymes \citePRH{comstock_direct_2015}, protein-ligand bond strength \citePRH{yuan_energy_2000}, and the energy landscapes of proteins and nucleic acids \citePRH{dudko_Theory_2008}. \pl

\begin{figure}
\centering
\includegraphics[width=\figwidth]{../Figures/Finals/cartoon.pdf}% Here is how to import EPS art
\caption[Diagram of AFM attachment geometry]{\fLabel{Cartoon}\pStartF Diagram of tip attachment geometry. (a1,a2) A diagram and force-extension curve corresponding to no attachments. (b1,b2) As previous, except illustrating a single attachment. (c1,c2) As previous, except illustrating multiple attachments. \pEndF }
\end{figure}


The analysis and interpretability of \singlemol{} experiments is limited by the attachment of the tip to the molecule of interest. Even with a high-concentration sample, quality \singlemol{} data between an attached molecule and commercially-available AFM tips are occur less than one curve in tens of thousands\cite{bosshart_reference-free_2012}. Attachment rates are improved by coating the AFM tip with a molecule exhibiting high binding affinity for the sample of interest (cite Rob XXX), but the majority of the data taken is still uninterpretable and must be filtered out. Filtering data without events is a major challenge in AFM data management and analysis.\pl

Methods exist to automate manually sorting \singlemol{} data and detect tip-sample events. Automation removes the burden of tedious data filtering and improves scientific reproducibility. Methods include alignment and binning in contour-length space\cite{kuhn_automated_2005,bosshart_reference-free_2012}, thresholding based on signal and noise characteristics \cite{gergely_semi-automatized_2001,roduit_openfovea:_2012} or wavelet transformations \cite{garcia-masso_automated_2016,benitez_searching_2017}, and classification schemes \cite{kasas_fuzzy_2000}. These methods do provide an increased degree of autonomy, but their use is limited by their lack of generalization and interpretability. In particular, contour-length alignment algorithms bias results towards the dominant features and necessarily require a polymer model for the contour length as a function of force and extension. In applications interested in novel biomolecules or rare behavior of a biomolecule, alignment algorithms will have limited use.  On the other hand, thresholding and classification-based algorithms generally require optimizing many hard-to-interpret parameters. As we show below, these optimizations do not generalize well to the typical range of \singlemol{} data (\fRef{Performance}).\pl

This paper describes a new method based on machine learning for detecting events in \singlemol{} force-extension curves.  The algorithm, named \name{} (Force Extension Automated Testable Hypothesis Event Recognition), require no \emph{a priori} knowledge of the polymer under study, does not bias interpretation of the data towards the dominant behavior of the data, and has a single, easy-to-interpret parameter which generalizes well to typical \singlemol{} data ranges.  In the first part of the paper, we describe the sample preparation, data acquisition, and data annotation needed to capture the unbinding of functionalized double-stranded DNA from functionalized AFM cantilevers (\fRef{Cartoon}). We then discuss manually annotating the unbinding events in the force-extension curves of the DNA at multiple pulling velocities, effective contour lengths, and events per curve (XXX cite available online? cite table giving data information?). Finally, we discuss the details of \name, an algorithm for automatically identifying events in force-extension curves and highlight its improved performance and timing relative to two other methods. \pl

\section{\sLabel{Materials}Materials and Methods}

\subsection{Sample Preparation}

\firstp Site-specific chemistry is used to improve the acquisition rate and quality of data. The procedure for surface, sample, and cantilever preparation has been described elsewhere (CITE XXX Rob) and in \sRef{SampleDetails}. Briefly, through polymerase chain reaction, double-stranded DNA is functionalized with DBCO at one end to ensure a covalent bond with an azide-functionalized surface. The polymer is also functionalized with biotin at the opposite end to ensure a specific but reversible bond with a streptavidin-coated cantilever. These two bonds ensure the tip-polymer bond is broken before the surface-polymer bond, preventing tip contamination. \pl

\subsection{\sLabel{Surface}Atomic force microscopy}

\firstp All atomic force microscopy measurements were carried out using an Asylum Cypher \supply{Asylum Research}{Cypher ES}. The spring constant and sensitivity were determined using the equipartition theorem method (cite XXX). All measurements were carried out with a 2 second pause at the surface at the pulling velocities noted in the text. To avoid possible non-uniform distributions of the sample in spaces, measurements were taken at points 1$\muup$m separated over a 30$\muup$m x 30$\muup$m grid.  \pl

\subsection{\sLabel{Annotation}Data annotation}


\begin{figure}
\centering
\includegraphics[width=\figwidth]{../Figures/Finals/ruptures.pdf}% Here is how to import EPS art
\caption[Definition of rupture force and loading rate]{\fLabel{Rupture} (a) A force extension curve with a shadow over an event. (b) The shadowed region of (a), with a linear fit of the data in region immediately proceeding the rupture region, which is shadowed. (c) The shadowed region from (b). The rupture point and rupture force are defined as the last data point above the linear fit in the fitting region. The loading rate is defined by the slope of the linear fit. }
\end{figure}


\firstp Two hundred force-extension curves with events were obtained at three different pulling velocities (100nm/s,500nm/s,1000nm/s). The start and end of each event in a curve, as indices offset from the start of the curve, were obtained through manual annotation. The curves and the events were saved into comma-separated value files and are available at (XXX link). (XXX table on data information) \pl 

The expected rupture forces and loading rates were calculated from the annotated data. This process is shown graphically in \fRef{Rupture}. The region leading up to the event start was fit by a line, with the region length set to 2\% of the number of points in the retract. The loading rate was assigned to the line`s slope, and the rupture force was calculated by the value of the line at the time value where the data was last above the line. This is the same procedure used to calculate the loading rate and rupture force of predicted events in \fRef{Performance}. \pl



\subsection{\sLabel{Algorithm}Algorithm Design}


\begin{figure}
  \begin{lstlisting}[language=Python]
def event_indices(force,threshhold):
   autocorrelation = [0,1] normalized autocorrelation of force
   med = median of autocorrelation
   autocorrelation_small_t = autocorrelation until reaching med
   $\tau$ = slope from line fit to log of autocorrelation_small_t
   N = number of points in force
   grid = array of points each spaced $\tau$ apart
   g$^{*}$ = second-order spline fit to force using grid for knots
   r = force - g$^{*}$
   n = number of points in force
   s[i] = standard deviation of r[max(0,i-$\tau$/2):min(i+$\tau$/2,n)]
   $\epsilon$ = median of s
   $\sigma$ = standard deviation of s within its interquartile region
   k = (s-$\epsilon$)/$\sigma$
   chebyshev = max(1,1/k$^2$)
   possible_events = indices where chebyshev <= threshhold
   # XXX: add in derivative filtering
   return possible_events
\end{lstlisting}
\caption[\name{} Psuedocode]{\noindent\fLabel{Code}\pStartF XXX code  \pEndF }
\end{figure}

\subsubsection{\sLabel{Metrics}Performance Metrics}

\firstp XXXNumber metrics were used for comparing the event-finding performance of \name with the human-annotated data. For clarity, we define the following, where `k' is one of the K total force-extension curves and `i' and `j' represent either true (t) or predicted (p): \pl

\eqs{ 
x_k &\equiv \text{the total displacement of the force extension curve} \\
d_{i\rightarrow j,k} &\equiv \text{ distribution of distances in `k' from `i' ruptures to the closest `j' ruptures in or $x_k$ if none } \\
q_{\text{x},i\rightarrow j} &\equiv \text{ the `x` percentile of } d_{i\rightarrow j} \text{ over all k } \\
\nu_i &\equiv \text{ distribution of `i' loading rates over all k} \\
F_i &\equiv \text{ distribution of `i' rupture forces over all k} \\
d_{(\nu,F),i} &\equiv \text{ joint probability distribution of $\nu_i$ and $F_i$ over all k} \\
 }

For example, $d_{t\rightarrow p,4}$ represents the distances from the true to the predicted events in force-extension curve 4, $\nu_t$ represents the distribution of true ruptures forces over all curves, and $d_{(\nu,F),p}$ represents the 2-d distribution of predicted points in the space of loading rates and rupture forces. Note that $F_{1,k}$ is the distance analogue to an $F_1$ score (XXX cite). The metrics we report, $F_{1,d}$ and $BC_{\nu,F}$ are defined in \tRef{metrics} and respectively give normalized estimates for how closely the distributions of predicted event locations and event properties align with the human-tagged data. \pl

\begin{table}
\begin{tabularx}{\textwidth}{ l | l | l | l | l }
\hline \hline
Shorthand & Description & Equation  & Range & \text{Optimum} \e 
Recall &  ?? &  &    & \e
BC$_{\nu,F}$ & Bhattacharyya Coefficient & $\braket{d_{(\nu,F),t}^{\frac{1}{2}}|d_{(\nu,F),p}^{\frac{1}{2}}}$ & [0,1] & 1 \e
\end{tabularx}
\caption[Definition of algorithmic performance metrics]{\tLabel{metrics} }
\end{table}

The metrics are constructed such $BC_{v,F}$ is one if and only if the joint distribution of rupture force and loading rates are equal. \pl


\begin{table}
\begin{tabularx}{\textwidth}{ l || l | l | l | l | l }
\hline \hline
 & bc2 & medtrue & medpred & qtrue & qpred \e \hline
no event & 0.966 & 4e-09 & 4.44e-09 & 1.45e-08 & 1.45e-08\e
open fovea & nan & -1 & -1 & -1 & -1\e
wavelet transform & 0.607 & 1.91e-07 & 2.05e-08 & 5.9e-08 & 5.9e-08\e
\end{tabularx}
\caption[Algorithm performance]{\tLabel{AppliedMetrics} Performance metrics} 
\end{table}


\subsection{\sLabel{Compare}Choice of competing methods}

XXX inttro

\firstp The following two algorithms were chosen for comparison: \pl

\begin{enumerate}
\item The AFM-specific `event\_find' routine from the OpenFovea AFM analysis package.\cite{roduit_openfovea:_2012}
\item The general-purpose `find\_peaks\_cwt' method from the Numerical Python package.
\end{enumerate}

 These methods were chosen to provide a representative sample of the viable techniques used in AFM data analysis. Unlike quadratic alignment algorithms in contour length space, these methods scale like O(N) and O(N$\cdot\log$(N)) respectively, where N is the length of a curve to be analyzed. Linear or near-linear scaling is desirable (see \fRef{Timing}) for analyzing hundreds of force-extension curves of hundreds of thousands of points each (XXX table). The baselines represent two common, distinct methods of event detection in AFM, since the OpenFovea method is a thresholding algorithm, and the Numerical Python method is wavelet-based algorithm. \pl

\subsection{\sLabel{Tuning}Algorithm tuning }

\firstp All three algorithms were tuned using 5-fold cross validation. Cross validation was performed at fifteen log-spaced parameters over the useful parameter range of the algorithms (\fRef{Tuning}). The parameter value minimizing the total number of missing and extra events for an algorithm was considered the algorithm's best parameter. Data shown in the results consists of the concatenation of all validation folds for each algoritm's best parameter.


\section{\sLabel{Results}Results}

\subsection{\sLabel{Timing}Algorithmic time complexity}

\firstp \fRef{Timing} compares the runtimes, T(n), of \name{} and the baselines. As expected, the runtime of each algorithm is roughly linear for in the region of interest, with \name{} having XXX  runtime coefficients.  \pl

\begin{figure}
\centering
\includegraphics[width=\figwidth]{../Figures/Finals/timing.pdf}% Here is how to import EPS art
\caption[Runtime versus length of curve]{\noindent\fLabel{Timing}\pStartF  Big-O runtime of each algorithm is approximately linear. (a) The runtime per curve versus number of points in the curve, T(N), for each algorithm is plotted as points. Lines around the data show the best-fit upper and lower bounds of the form T$_{\mathrm{upper}}$(n) = a$_0$ + 2a$_1$n  and T$_{\mathrm{lower}}$(n) = a$_0$ + $\frac{1}{2}$a$_1$n. (b) The linear constants $a_1$, representing the asymptotic runtime per data point, for each algorithm from (a) are plotted. \pEndF}
\end{figure}

\subsection{\sLabel{Performance}Algorithmic event detection performance}



\begin{figure}
\centering
\includegraphics[width=\figwidth]{../Figures/Finals/landscape.pdf}% Here is how to import EPS art
\caption[Algorithm Performance]{\noindent\fLabel{Performance}\pStartF Performance of this algorithm compared to the baseline algorithms. (a1) The distributions of distances from predicted to true points d$_{\mathrm{p}\rightarrow\mathrm{t}}$ and from true to predicted points, d$_{\mathrm{t}\rightarrow\mathrm{p}}$ for \name{}. (a2) \name{}`s two-dimensional distribution of predicted and actual rupture force and loading rate, as defined by (XXX). (a3 and a4) The histograms of rupture forces and loading rates, respectively, for \name{}.  (a5) The Bhattacharya coefficiences for (XXX). (b1-b5): As a1-a5, but for OpenFovea. (c1-c5): As a1-a5, but for Numerical Python \pEndF }
\end{figure}



\section{\sLabel{Discussion}Discussion}


\firstp \pl

\subsubsection{\sLabel{Beer}XRF depends on wavelength and element}

\firstp \pl

\clearpage

\section{References}



\clearpage

Bibliography 

\section{Bibliography}

\bibliography{0ms-citations} 


\clearpage

\section{Appendix}

%restarct numbering for appendix
\renewcommand{\thepage}{S\arabic{page}} 
\renewcommand{\thesection}{S\arabic{section}}  
\renewcommand{\thetable}{S\arabic{table}}  
\renewcommand{\thefigure}{S\arabic{figure}} 
\setcounter{figure}{0}
\setcounter{table}{0}


\subsection{\sLabel{SampleDetails}Sample and Cantilever Preparation}


\begin{table}
\begin{tabularx}{\textwidth}{ l | l  }
\hline \hline
Forward primer & Dagttgttcctttctattctcactccgc \\ \e 
Reverse primer & BtcaataaTcggctgtctTtccttatcaTtc \\ \e 
\end{tabularx}
\caption[DNA primer sequences]{\tLabel{Sequences}Sequences for single-stranded DNA construct and for double-stranded DNA primers. The forward and reverse primers amplify a 647nm piece of DNA, from positions 1607 to 3520 on the M13mp18 plasmid, as discussed in the next. Unmodified DNA bases are lowercase. The uppercase letters `T',`B', and `D' respectively represent biotinylated Thymidine residues, a terminal Biotin separated from the sequence by triethyleneglycol spacer, and a terminal Dibenzocyclooctyl separated from the sequence by triethyleneglycol spacer.}
\end{table}


\subsubsection{\sLabel{Surface}Azide-functionalied surfaces}

\firstp Glass surfaces were smoothed using Potassium Hydroxide etching as follows. 12mm diameter glass disks \supply{Ted Pella}{26023} were sonicated \supply{Branson}{2510} for 5 minutes in 250mL of 95\% ethanol \supply{Decon}{2801}, sonicated  for 5 minutes in 250mL of ACS grade acetone \supply{Fisher}{A18-4}, and transferred to a solution of 80g of Potassium Hydroxide \supply{Fisher}{P250-500} dissolved in  170mL of 65\% ethanol and 80mL of deionized water \supply{Barnstead}{GenPure Pro} for 3 minutes. To removed residual KOH, the glass was serially diluted in two 1L beakers of 18.2M$\Omega$ deionized water. The etched surfaces were dried with 99.8\% pure Nitrogen gas \supply{Airgas}{NI UHP-300} and stored at room temperature in a dust-proof box. \pl

To create azide-functionalized surfaces, etched glass was activated using 30 minutes exposure in a UV-ozone chamber \supply{Novascan}{PSDP Digital UV Ozone System} and incubated for three hours in a 70mL, 60\degreeC{} solution of 0.15mg/mL 600Dalton Silane-PEG-Azide \supply{Nanocs}{PG2-AZSL-600} dissolved in toluene \supply{Sigma}{179418-4L}. The surfaces were then mounted in a custom-made teflon-holder and rinsed serially in 250mL of toluene, isopropanol \supply{Fisher}{A416-4}, and deionized water. The azide-functionalized surfaces were dried with Nitrogen gas and stored in a dust-proof container at 4\degreeC{}. \pl 

\subsubsection{\sLabel{Sample}DNA Samples}

\firstp For the 1914bp double-stranded DNA, the 1607 forward-sense and 3520 reverse-sense primers (\tRef{Sequences}) for the M13mp18 plasmid \supply{New England BioLabs}{N4018S} were obtained from Integrated DNA Technologies  and used for polymerase-chain reaction \supply{Millipore}{71086-4} using 40 cycles on a thermocycler \supply{Bio-Rad}{T100}. The reverse-sense primer was modified to include three biotinylated thyimine bases and a 5-prime biotin after a PEG spacer, and the forward-sense primer was modified to include a 5-prime DBCO after a PEG-spacer (see \tRef{Sequences}). After the PCR product was purified \supply{Qiagen}{28106} and the 1.9kbp band selected by 2\% gel electrophoresis \supply{Sigma}{A9539-500}, the agarose was eluted out \supply{Bio-Rad}{732-6165}, the DNA solution was concentrated \supply{Millipore}{UFC501096}, purified \supply{Qiagen}{28106}, and stored at 4\degreeC{} in a solution of TE, 10mM Tris \supply{Fisher}{BP151-1} and 1mM EDTA \supply{Fisher}{S311-500} at pH 8.0. The typical recovery efficiency of this procedure was 25\%. \\

The purity of the DNA was verified by depositing 20pmol of DNA in imaging buffer (3mM Nickel (XXX), 10mM Hepes (XXX) at pH 7) onto freshly-cleaved mica for 30 minutes, rinsing serially 5 times with 1mL of deionized water and 5 times with imaging buffer (XXX) and imaging (XXX figure)\pl 

For DNA deposition, 20uL of the desired concentration of DNA (see section XXX) was mixed with 80uL of TE at pH 8.0 and deposited onto azide-functionalized glass (see \sRef{Surfaces}) affixed with epoxy \supply{Devcon}{14250} to specimen disks \supply{Ted Pella}{16218} and incubated at 4C for 15 hours. The surfaces were rinsed by 7mL of TE pH 8.0 and 7mL of PBS with 1mM EDTA at pH 7.4, and stored at 4\degreeC{}. 

\subsubsection{\sLabel{Cantilevers}Streptravidin-functionalized cantilevers}

\firstp Functionalized cantilevers with nominal spring constants of 4 $\frac{\text{pN}}{nm}$  were used for all experiments. Functionalization etches away gold to improve force stability (XXX cite) and covalently attaches streptatividin to the etched cantilevers to improve attachment to the biotinylated DNA. Commercially available cantilevers \supply{Asylum Research}{BL-RC-150VB} were serially rinsed for 30 seconds in 50mL of gold etchant \supply{Transene}{TFA}, 250mL of deionized water, 50mL of chromium etchant \supply{Transene}{1020}, 250mL of deionized water, and one final rinse in 250mL of deionized water. After drying, the tips were activated using 30 minutes exposure in a UV-Ozone chamber and incubated for three hours in a 70mL, 60\degreeC{} solution of 0.15mg/mL 600Dalton Silane-PEG-Maleimide \supply{Nanocs}{PG2-MLSL-600} dissolved in toluene. The maleimide-functionalized tips were serially rinsed in 50mL of toluene, isopropanol, water, immediately dried \supply{KimTech}{5511}, and immersed for three hours in a 0.4mg/mL solution of thiol-streptavidin \supply{Protein Mods}{SAVT} in PBS \supply{Millipore}{524650} at pH 6.75 with 1mM TCEP \supply{Thermo Scientific}{77720} at room temperature in a moisture-proof container. The tips were then tranferred to 4\degreeC{} for 15 hours. After the 4\degreeC{} incubation, to remove free streptavidin, the tips were serially rinsed in two 10mL beakers of PBS at pH 7.4 and submerged in a 20mL petri dish of PBS for 10 minutes. The tips were then stored in 50$\muup$L of PBS at 4C in plastic wafers \supply{Entegris}{H22-10/1-0615} until loading into the atomic force microscope. \pl


\subsection{Algorithm Design}

This section details the mathematics and choices behind the event-detection algorithm. The following conventions are followed:

\begin{enumerate}
 \item All variables with uppercase letters are random variables.
 \item All variables with lowercase letters are either instances of the corresponding uppercase random variables (i.e., measurements) or pure functions.
 \item All variables with a hat (e.g. $\hat{\epsilon}_t$) are empirical measurements or estimated of an already-defined variable .
\end{enumerate}

\subsubsection{Defining the no-event hypothesis}

\firstp We define an event as when the time derivative of force applied to a molecule exhibits a discontinuity as the molecule passes over a free-energy barrier. We assume this event takes place on timescales much smaller than the response time of the probe. If this is not true, the data assumed smoothed until this condition is reached. The algorithm models the data assuming no event is occurring at a given time `t' and finds where the probability of a measurement is low. Hereafter, the definition of an event and the assumptions of no event at a given time will be referred to as the \emph{no-event hypothesis}. 

\subsubsection{Mathematical background for testing the no-event hypothesis}

\firstp Under the no-event hypothesis, the noise-dependent distribution of force `F' for a discrete series of forces sampled at points t can be well-approximated by the sum of a smooth signal and an noise distribution (\fRef{FeatherExample}):

\eqs{ F_t = g_t + X(0,\sigma^2) }

where `g$_t$' is a smooth function with a continuous first derivative and `X' is a random variable with zero mean and variance $\sigma^2$. The closed form of the smooth signal and the noise distribution are assumed unknown and can vary from one force extension curve to the next. If `$g^{*}_t$' is a function with a continuous first derivative approximately equal to $g_t$ such that $\forall t,\epsilon_t\equiv|g^{*}_t-g_t|$ for real $\epsilon_t\ge 0$, then we define an error distribution $R_t$ such that: \pl

\eqs{ R_t \equiv F_t - g^{*}_t = \epsilon_t + X(0,\sigma) }

where

\eqlab{ E[R_t^2] -E[R_t]^2 = [(g_t-g^{*}_t)^2 + E[X(0,\sigma)^2]] - (g_t-g^{*}_t)^2  = \sigma^2 }{feather-sigma}

and 

\eqlab{ |E[R_t]| = \epsilon_t \le E[|R_t|] }{feather-epsilon}

In practice (see \fRef{FeatherExample}), we approximate $\epsilon_t$ by the average over all time points $\hat{\epsilon}_t \approx \langle \epsilon_t \rangle_{\text{all t}} = \frac{1}{N} \sum_{t=1}^N |r_t|$. Under this assumption, the probability `P' of measuring $r_t$ is bounded by Chebyshev's inequality is:

\eqlab{ P( |R_t-\epsilon_t| \ge r_t-\epsilon_t ) \le
 (\frac{\sigma}{r_t-\epsilon_t})^2 }{feather-probability}


For \emph{any} noise distribution, this bounds the probability of a measurement under the no-event hypothesis, given the force approximation $g^{*}_t$ (which in turn yields the estimator error $\hat{\epsilon}$ and the noise $\hat{\sigma}$ by \eRef{feather-epsilon} and \eRef{feather-sigma}). A low probability at a given time implies the measurement is unlikely under the no-event hypothesis. \pl

\subsubsection{Accurate estimators for hypothesis testing}

XXX auto correlation time motivation \pl 

The approximation to the noiseless force $g^{*}_t$ is obtained by fitting a least-squares second-order basis spline (b-spline, ) to the force versus time curve. The spline is second-order to ensure a continuous first derivative (\fRef{FeatherExample}), and the spline knots are spaced uniformly at intervals of $\tau$. \fRef{FeatherExample} is a representative demonstration of the spline fitting. Determining  $g^{*}_t$ immediately gives $\hat{r}_t$ by  \eRef{feather-sigma}, \eRef{feather-epsilon}, and \eRef{feather-probability}. \pl

Using $r_t$ as shown in \eRef{feather-epsilon} does not provide a strong signal in the presence of an event (see \fRef{FeatherExample}). In order to improve the method, the distribution of windowed standard deviations `$s_t$' of $r_t$ centered at t with a window of $[-\frac{\tau}{2},\frac{\tau}{2}]$ was used in place of $r_t$. Using $s_t$ instead of $r_t$ provides a much stronger signal in the presence of an event (see \fRef{FeatherExample}).  \pl

The noise variables $\sigma$ and $\epsilon$ are estimated from the distribution of standard deviations $s_t$ on the region of the approach curve without the surface hard-contact. From this distribution, $\hat{\sigma}$ is set to the standard deviation of $s_t$ and $\hat{\epsilon}$ is approximated by the median. The median is used instead of the mean in order to remove the influence of possible false-positive events in the approach due to stage noise. The removal of these psuedo-events is necessary to ensure accurate estimations for $\sigma$ and $\epsilon$, which are based on the no-event hypothesis.


\begin{figure}
\centering
\includegraphics[width=\figwidth]{../Figures/Finals/algorithm.pdf}% Here is how to import EPS art
\caption[\name{} algorithmic pipeline]{\noindent\fLabel{FeatherExample}\pStartF Algorithm experiment \pEndF }
\end{figure}


XXX table?

\subsubsection{Improvements}

XXX figure out how to determine where the adhesion ends, how to improve SNR by derivative stuffs.


\begin{figure}
\centering
\includegraphics[width=\figwidth]{../Figures/Finals/prep.pdf}% Here is how to import EPS art
\caption[Verification of sample purity]{\noindent\fLabel{Prep}\pStartF Purity of the sample preparation. \pEndF }
\end{figure}


\begin{figure}
\centering
\includegraphics[width=\figwidth]{../Figures/Finals/tuning.pdf}% Here is how to import EPS art
\caption[Cross validation of algorithms and optimal parameters]{\noindent\fLabel{Tuning}\pStartF Details of tuning experiments\pEndF }
\end{figure}



\begin{figure}
\centering
\includegraphics[width=\figwidth]{../Figures/Finals/supplemental.pdf}% Here is how to import EPS art
\caption[Algorithmic runtime versus loading rate]{\noindent\fLabel{Timing_Details}\pStartF Details of timing experiments\pEndF }
\end{figure}



\end{document}

%
% XXX difference wrt to solids. Auger, no space? \\

%

%
% ****** End of file aipsamp.tex ******
